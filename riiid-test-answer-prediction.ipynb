{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import gc\n",
    "from collections import deque\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pd.options.display.max_columns=40\n",
    "pd.options.display.max_rows=130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Riiid:\n",
    "    \n",
    "    dtype={'row_id': 'int64', 'timestamp': 'int64',\n",
    "           'user_id': 'int32', 'content_id': 'int16',\n",
    "           'content_type_id': 'int8', 'task_container_id': 'int16',\n",
    "           'user_answer': 'int8', 'answered_correctly': 'int8',\n",
    "           'prior_question_elapsed_time': 'float32',\n",
    "           'prior_question_had_explanation': 'boolean',\n",
    "          }\n",
    "    \n",
    "    usecols=['row_id', 'timestamp', 'user_id', 'content_id',\n",
    "             'content_type_id','task_container_id',\n",
    "             'answered_correctly',\n",
    "             'prior_question_elapsed_time','prior_question_had_explanation']\n",
    "    \n",
    "    questions_df = None\n",
    "    tb = None\n",
    "    tpq = None\n",
    "    tptc = None\n",
    "    \n",
    "    user_hist_dict = {}\n",
    "    content_hist_dict = {}\n",
    "    \n",
    "    features = None\n",
    "    _na_dict = None\n",
    "    _dtype_dict = None\n",
    "\n",
    "    def __init__(self, path):\n",
    "        Riiid.path = Path(path)\n",
    "\n",
    "    def setup(self, path):\n",
    "\n",
    "        with open(Path(path)/'data/questions_df.pickle', mode='rb') as file:\n",
    "            Riiid.questions_df = pickle.load(file)\n",
    "            \n",
    "        with open(Path(path)/'data/tb.pickle', mode='rb') as file:\n",
    "            Riiid.tb = pickle.load(file)\n",
    "        with open(Path(path)/'data/tpq.pickle', mode='rb') as file:\n",
    "            Riiid.tpq = pickle.load(file)\n",
    "#         with open(Path(path)/'data/tptc.pickle', mode='rb') as file:\n",
    "#             Riiid.tptc = pickle.load(file)        \n",
    "                 \n",
    "        with open(Path(path)/'data/data_min.pickle', mode='rb') as file:\n",
    "            train_df = pickle.load(file)\n",
    "            \n",
    "        self._get_history_dict(train_df)\n",
    "        del train_df\n",
    "        gc.collect()\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def _proc_question_tags(df):\n",
    "        return pd.concat([df.drop('tags', 1), df['tags'].str.get_dummies(sep=\" \")], 1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_streak(s):\n",
    "        prev = 0\n",
    "        streak = 0\n",
    "        for i in s:\n",
    "            if i == 0:\n",
    "                streak = streak - 1 if prev == 0 else -1\n",
    "            elif i == 1:\n",
    "                streak = streak + 1 if prev == 1 else 1\n",
    "            else: # lecture\n",
    "                continue\n",
    "            prev = i\n",
    "        return streak\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_history_dict(df):\n",
    "        \n",
    "        #shift target\n",
    "        df['answered_correctly'] = df[['user_id', 'answered_correctly']].groupby('user_id').shift()\n",
    "        df['answered_correctly'] = df['answered_correctly'].fillna(0).astype(np.int8)\n",
    "        gc.collect()\n",
    "         \n",
    "        target_sum = df[['user_id', 'answered_correctly']].groupby('user_id').sum().values.astype(np.int16)\n",
    "        target_count = df[['user_id', 'answered_correctly']].groupby('user_id').count().values.astype(np.int16)\n",
    "        user_targets = df.groupby('user_id')['answered_correctly'].apply(np.array)\n",
    "        \n",
    "        timestamp = df.groupby('user_id')['timestamp'].max().values.astype(np.int64)\n",
    "        df['prior_question_elapsed_time_cumsum'] = df[['user_id',\n",
    "                                                  'prior_question_elapsed_time']]\\\n",
    "            .groupby('user_id').transform('cumsum')\n",
    "        \n",
    "        prior_question_elapsed_cumsum = df[['user_id',\n",
    "                                            'prior_question_elapsed_time_cumsum']]\\\n",
    "            .groupby('user_id').max().values.astype(np.int64)\n",
    "    \n",
    "        # fill dictionary with default values\n",
    "        for user_id in df['user_id'].unique():\n",
    "            Riiid.user_hist_dict[user_id] = {}\n",
    "        \n",
    "        # add user content attempts\n",
    "        user_content = df.groupby('user_id')['content_id'].apply(np.array).apply(np.sort).apply(np.unique)\n",
    "        user_attempts = df.groupby(['user_id', 'content_id'])['content_id'].count()\\\n",
    "            .astype(np.uint8).groupby('user_id').apply(np.array).values\n",
    "        user_attempts -= 1\n",
    "    \n",
    "        for user_id, content, attempt in zip(Riiid.user_hist_dict.keys(), user_content, user_attempts):\n",
    "            Riiid.user_hist_dict[user_id]['n_attempts'] = dict(zip(content, attempt))\n",
    "        \n",
    "        del user_content, user_attempts\n",
    "        gc.collect()\n",
    "        \n",
    "        def _get_streak(s):\n",
    "            prev = 0\n",
    "            streak = 0\n",
    "            for i in s:\n",
    "                if i == 0:\n",
    "                    streak = streak - 1 if prev == 0 else -1\n",
    "                elif i == 1:\n",
    "                    streak = streak + 1 if prev == 1 else 1\n",
    "                else: # lecture\n",
    "                    continue\n",
    "                prev = i\n",
    "            return streak\n",
    "    \n",
    "        for idx, user_id in enumerate(Riiid.user_hist_dict.keys()):\n",
    "            Riiid.user_hist_dict[user_id]['user_sum'] = target_sum[idx][0]\n",
    "            Riiid.user_hist_dict[user_id]['user_count'] = target_count[idx][0]\n",
    "            Riiid.user_hist_dict[user_id]['user_mean'] = (Riiid.user_hist_dict[user_id]['user_sum'] /\n",
    "                                               Riiid.user_hist_dict[user_id]['user_count']).astype(np.float16)\n",
    "            \n",
    "            Riiid.user_hist_dict[user_id]['user_L10'] = deque(user_targets.loc[user_id], maxlen=10)\n",
    "            Riiid.user_hist_dict[user_id]['user_L10_mean'] = np.mean(Riiid.user_hist_dict[user_id]['user_L10'])\\\n",
    "                .astype(np.float16)\n",
    "            Riiid.user_hist_dict[user_id]['user_streak'] = _get_streak(user_targets.loc[user_id])\n",
    "            \n",
    "            Riiid.user_hist_dict[user_id]['timestamp'] = timestamp[idx]\n",
    "            Riiid.user_hist_dict[user_id]['prior_question_elapsed_time_cumsum'] = prior_question_elapsed_cumsum[idx][0]\n",
    "\n",
    "        del timestamp, prior_question_elapsed_cumsum\n",
    "        del target_sum, target_count, user_targets\n",
    "        gc.collect()\n",
    "\n",
    "    @classmethod\n",
    "    def _set_up_questions_df(cls, train):\n",
    "        \"\"\"Create questions_df using stats from train.\"\"\"\n",
    "        \n",
    "        cls.questions_df = pd.read_csv(cls.path/'questions.csv')\n",
    "        \n",
    "        # drop columns\n",
    "        cls.questions_df = cls.questions_df.drop(columns=['correct_answer'])\n",
    "        \n",
    "        # add number of tags\n",
    "        cls.questions_df['num_of_tags'] = cls.questions_df['tags'].map(lambda x: len(str(x).split()))\n",
    "        \n",
    "        # encode tags\n",
    "        cls.questions_df = cls.questions_df.fillna({'tags':str(-1)})\n",
    "        cls.le = LabelEncoder()\n",
    "        cls.questions_df['tags'] = cls.le.fit_transform(cls.questions_df['tags'])\n",
    "        \n",
    "        # add number of questions in bundle\n",
    "        tmp = cls.questions_df[['question_id', 'bundle_id']] \\\n",
    "            .groupby('bundle_id').count() \\\n",
    "            .rename(columns={'question_id':'bundle_size'})\n",
    "        \n",
    "        cls.questions_df = cls.questions_df.join(tmp, on='bundle_id') \n",
    "\n",
    "        # add content stats\n",
    "        stats = train.loc[train['content_type_id']==0, ['content_id', 'answered_correctly']] \\\n",
    "            .groupby('content_id').agg(['mean', 'std', 'skew'])\n",
    "        \n",
    "        stats.columns = stats.columns.droplevel()\n",
    "        stats.columns = ['question_mean', 'question_std', 'question_skew']\n",
    "        stats = stats.astype({'question_mean':'float16',\n",
    "                              'question_std':'float16','question_skew':'float16'})\n",
    "        \n",
    "        cls.questions_df = cls.questions_df.join(stats, on='question_id')\n",
    "        \n",
    "        # add bundle stats\n",
    "        tmp = cls.questions_df[['question_id', 'bundle_id']].set_index(keys='question_id')\n",
    "        train = train.join(tmp, on='content_id')\n",
    "        stats = train.loc[train['content_type_id']==0, ['bundle_id', 'answered_correctly']] \\\n",
    "            .groupby('bundle_id').agg(['mean', 'std', 'skew'])\n",
    "        \n",
    "        stats.columns = stats.columns.droplevel()\n",
    "        stats.columns = ['bundle_mean', 'bundle_std', 'bundle_skew']\n",
    "        stats = stats.astype({'bundle_mean':'float16',\n",
    "                              'bundle_std':'float16','bundle_skew':'float16'})\n",
    "        \n",
    "        cls.questions_df = cls.questions_df.join(stats, on='bundle_id')\n",
    "\n",
    "        # add tags stats\n",
    "        tmp = cls.questions_df[['question_id', 'tags']].set_index(keys='question_id')\n",
    "        train = train.join(tmp, on='content_id')\n",
    "        stats = train.loc[train['content_type_id']==0, ['tags', 'answered_correctly']] \\\n",
    "            .groupby('tags').agg(['mean', 'std', 'skew'])\n",
    "        \n",
    "        stats.columns = stats.columns.droplevel()\n",
    "        stats.columns = ['tags_mean', 'tags_std', 'tags_skew']\n",
    "        stats = stats.astype({'tags_mean':'float16',\n",
    "                              'tags_std':'float16','tags_skew':'float16'})\n",
    "        \n",
    "        cls.questions_df = cls.questions_df.join(stats, on='tags')       \n",
    "        \n",
    "        # fillna\n",
    "        cls.questions_df = cls.questions_df.fillna(\n",
    "            {'tags':str(-1),\n",
    "             'question_mean':cls.questions_df['question_mean'].mean(),\n",
    "             'question_std':cls.questions_df['question_std'].mean(),\n",
    "             'question_skew':cls.questions_df['question_skew'].mean(),\n",
    "             'bundle_mean':cls.questions_df['bundle_mean'].mean(),\n",
    "             'bundle_std':cls.questions_df['bundle_std'].mean(),\n",
    "             'bundle_skew':cls.questions_df['bundle_skew'].mean(),\n",
    "             'tags_mean':cls.questions_df['tags_mean'].mean(),\n",
    "             'tags_std':cls.questions_df['tags_std'].mean(),\n",
    "             'tags_skew':cls.questions_df['tags_skew'].mean()})\n",
    "        \n",
    "        # set_index to question_id for optimised join\n",
    "        cls.questions_df = cls.questions_df.set_index('question_id', verify_integrity=True)\n",
    "        \n",
    "\n",
    "        \n",
    "    @classmethod\n",
    "    def load_and_process_lectures(cls):\n",
    "        \n",
    "        cls.lectures_df = pd.read_csv(cls.path/'lectures.csv')\n",
    "\n",
    "        # process lectures data\n",
    "        cls.lectures_df['type_of'] = cls.lectures_df['type_of'].astype('category')\n",
    "#         types_of = ('type_starter', 'type_concept', 'type_intention', 'type_solving question')\n",
    "#         cls.lectures_df['type_of'].cat.set_categories(types_of, ordered=False, inplace=True)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _scan_user_data(hist, df):\n",
    "        \n",
    "        # prev\n",
    "        user_mean, user_sum, user_count = [], [], []\n",
    "        user_L10_mean,  user_streak = [], []\n",
    "        # current\n",
    "        n_attempts= []\n",
    "        time_between = []\n",
    "        prior_question_elapsed_time_cumsum = []\n",
    "\n",
    "    \n",
    "        for idx, (user_id, content_id, content_type_id,\n",
    "                  timestamp, prior_question_elapsed_time) in df[['user_id', 'content_id',\n",
    "                                                                 'content_type_id', 'timestamp',\n",
    "                                                                 'prior_question_elapsed_time']].iterrows():\n",
    "            # fill in dummy for lectures\n",
    "            if content_type_id:\n",
    "                n_attempts.append(0)\n",
    "                user_mean.append(0.)\n",
    "                user_sum.append(0)\n",
    "                user_count.append(0)\n",
    "                user_L10_mean.append(0.)\n",
    "                user_streak.append(0)\n",
    "                \n",
    "                time_between.append(0)\n",
    "                prior_question_elapsed_time_cumsum.append(0)\n",
    "                continue\n",
    "\n",
    "            # check if user exists\n",
    "            if user_id in hist:\n",
    "                # check if user already answered the question, if so update it to a maximum of 4\n",
    "                if content_id in hist[user_id]['n_attempts']:\n",
    "                    hist[user_id]['n_attempts'][content_id] = min(4, hist[user_id]['n_attempts'][content_id] + 1)\n",
    "                # if user did not answered the question already, set the number of attempts to 0\n",
    "                else:\n",
    "                    hist[user_id]['n_attempts'][content_id] = 0\n",
    "                    \n",
    "                hist[user_id]['prior_question_elapsed_time_cumsum'] += prior_question_elapsed_time\n",
    "        \n",
    "            # else create user with default values\n",
    "            else:\n",
    "                dict_keys = ['user_mean', 'user_sum', 'user_count',\n",
    "                             'user_L10', 'user_L10_mean', 'user_streak',\n",
    "                             'n_attempts', \n",
    "                             'timestamp', 'prior_question_elapsed_time_cumsum', 'tb']\n",
    "                dict_default_vals = [0, 0, 1, deque(maxlen=10), 0, 0, dict(zip([content_id],[0])),\n",
    "                                     timestamp, prior_question_elapsed_time, 0]\n",
    "                hist[user_id] = dict(zip(dict_keys, dict_default_vals))\n",
    "            \n",
    "            # add user data to lists\n",
    "            n_attempts.append(hist[user_id]['n_attempts'][content_id])\n",
    "            user_mean.append(hist[user_id]['user_mean'])\n",
    "            user_sum.append(hist[user_id]['user_sum'])\n",
    "            user_count.append(hist[user_id]['user_count'])\n",
    "            user_L10_mean.append(hist[user_id]['user_L10_mean'])\n",
    "            user_streak.append(hist[user_id]['user_streak'])\n",
    "\n",
    "            prior_question_elapsed_time_cumsum.append(hist[user_id]['prior_question_elapsed_time_cumsum'])\n",
    "            \n",
    "            if timestamp > hist[user_id]['timestamp']:\n",
    "                time_between.append(timestamp - hist[user_id]['timestamp'])\n",
    "                hist[user_id]['tb'] = timestamp - hist[user_id]['timestamp']\n",
    "                hist[user_id]['timestamp'] = timestamp\n",
    "            elif timestamp == hist[user_id]['timestamp']:\n",
    "                time_between.append(hist[user_id]['tb'])\n",
    "            else: # This should not happen\n",
    "                raise ValueError('Current timestamp is lower then previous')\n",
    "                \n",
    "        \n",
    "        return (user_mean, user_count, user_sum, n_attempts,\n",
    "                time_between, prior_question_elapsed_time_cumsum,\n",
    "                user_L10_mean, user_streak)\n",
    "            \n",
    "    def update_hist_data(self, prev_test_df):\n",
    "        for (user_id, content_id,\n",
    "             content_type_id, answered_correctly) in prev_test_df[['user_id', 'content_id',\n",
    "                                                                 'content_type_id','answered_correctly']].values:\n",
    "            # skip lectures\n",
    "            if content_type_id:\n",
    "                continue\n",
    "        \n",
    "            # update user features\n",
    "            Riiid.user_hist_dict[user_id]['user_sum'] += answered_correctly\n",
    "            Riiid.user_hist_dict[user_id]['user_mean'] = np.float16(Riiid.user_hist_dict[user_id]['user_sum'] /\n",
    "                                                 Riiid.user_hist_dict[user_id]['user_count'])\n",
    "            Riiid.user_hist_dict[user_id]['user_count'] += 1\n",
    "            Riiid.user_hist_dict[user_id]['user_L10'].append(answered_correctly)\n",
    "            Riiid.user_hist_dict[user_id]['user_L10_mean'] = np.mean(Riiid.user_hist_dict[user_id]['user_L10'])\n",
    "            \n",
    "            if answered_correctly:\n",
    "                if Riiid.user_hist_dict[user_id]['user_streak'] > 0:\n",
    "                    Riiid.user_hist_dict[user_id]['user_streak'] += 1\n",
    "                else:\n",
    "                    Riiid.user_hist_dict[user_id]['user_streak'] = 1\n",
    "            else:\n",
    "                if Riiid.user_hist_dict[user_id]['user_streak'] < 0:\n",
    "                    Riiid.user_hist_dict[user_id]['user_streak'] -= 1\n",
    "                else:\n",
    "                    Riiid.user_hist_dict[user_id]['user_streak'] = -1                \n",
    "            \n",
    "    \n",
    "    def transform_data(self, df, inference=True, verbose=False):\n",
    "        \n",
    "        if not inference: # we need questions and lectures for inference\n",
    "            # step 0 = keep questions only\n",
    "            df = df.loc[df['content_type_id']==0]\n",
    "            if verbose: print('step 0 (keep questions only) - Done')\n",
    "        gc.collect()\n",
    "\n",
    "        # step 1 = fillna for prior_question_elapsed_time and prior_question_had_explanation\n",
    "        df = df.fillna({'prior_question_elapsed_time':0.,\n",
    "                        'prior_question_had_explanation':False})\n",
    "        if verbose: print('step 1 (fillna: prior_question_elapsed_time & prior_question_had_explanation) - Done')\n",
    "        \n",
    "        df['days'] = np.floor(df['timestamp']/(1000*60*60*24))\n",
    "  \n",
    "        # step 3 add historical features\n",
    "        if inference:\n",
    "            \n",
    "            (user_mean, user_count, user_sum, n_attempts,\n",
    "             time_between, prior_question_elapsed_time_cumsum,\n",
    "             user_L10_mean, user_streak) = self._scan_user_data(Riiid.user_hist_dict, df)\n",
    "            \n",
    "            # prev\n",
    "            df['target_cumcount'] = user_count\n",
    "            df['target_cumsum'] = user_sum\n",
    "            df['user_mean'] = user_mean\n",
    "            df['user_L10_mean'] = user_L10_mean\n",
    "            df['user_streak'] = user_streak\n",
    "            \n",
    "            # current\n",
    "            df['n_attempts'] = n_attempts\n",
    "            df['time_between'] = time_between\n",
    "            df['prior_question_elapsed_time_cumsum'] = prior_question_elapsed_time_cumsum\n",
    "            \n",
    "            df['lag_time'] = df['time_between'] - df['prior_question_elapsed_time']\n",
    "\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # shift target\n",
    "            df['answered_correctly'] = df[['user_id', 'answered_correctly']].groupby('user_id').shift()\n",
    "            df['answered_correctly'] = df['answered_correctly'].fillna(0).astype(np.int8)\n",
    "            gc.collect()\n",
    "            \n",
    "            # user_streak\n",
    "            def f(df):\n",
    "                df['c-'] = (df['answered_correctly'] == 1).cumsum()\n",
    "                df['c+'] = (df['answered_correctly'] == 0).cumsum()\n",
    "\n",
    "                df['user_streak'] = (-((df['c-'] == 0).astype(int) + df.groupby('c-').cumcount())\n",
    "                    + (df['c+'] == 0).astype(int) + df.groupby('c+').cumcount())\n",
    "\n",
    "                return df            \n",
    "            df = df.groupby('user_id').apply(f)\n",
    "            df = df.drop(columns=['c-', 'c+'])\n",
    "            gc.collect()\n",
    "            \n",
    "            \n",
    "            df['user_L10_mean'] = df[['user_id', 'answered_correctly']].groupby('user_id')\\\n",
    "                .rolling(10, min_periods=1).mean()['answered_correctly'].values.astype(np.float16)\n",
    "            \n",
    "            \n",
    "            df['time_between'] = df[['user_id', 'timestamp']]\\\n",
    "                .groupby('user_id').transform('diff').fillna(0.).astype(int)\n",
    "            df['time_between'] = df[['user_id', 'timestamp', 'time_between']]\\\n",
    "                .groupby(['user_id', 'timestamp']).transform('first')\n",
    "            gc.collect()\n",
    "            \n",
    "            df['lag_time'] = df['time_between'] - df['prior_question_elapsed_time']\n",
    "            \n",
    "            \n",
    "            df['target_cumcount'] = df[['user_id', 'answered_correctly']]\\\n",
    "                .groupby(['user_id']).transform('cumcount').astype(np.int16) + 1\n",
    "            df['target_cumsum'] = df[['user_id', 'answered_correctly']]\\\n",
    "                .groupby('user_id').transform('cumsum').astype(np.int16)\n",
    "            df['user_mean']=(df['target_cumsum'] / df['target_cumcount']).astype(np.float16)\n",
    "            \n",
    "            \n",
    "            df['prior_question_elapsed_time_cumsum'] = df[['user_id', 'prior_question_elapsed_time']]\\\n",
    "                .groupby('user_id').transform('cumsum').astype(int)\n",
    "\n",
    "            df['n_attempts'] = df[['user_id', 'content_id', 'answered_correctly']]\\\n",
    "                            .groupby(['user_id', 'content_id']).transform('cumcount').astype('uint8')\n",
    "            df['n_attempts'] = df['n_attempts'].clip(lower=None, upper=4)\n",
    "            gc.collect()\n",
    "            \n",
    "        if verbose: print('step 3 (add historical features) - Done')\n",
    "\n",
    "    \n",
    "        # step 4 add ratios\n",
    "        df['time_per_question']=np.float32(df['prior_question_elapsed_time_cumsum'] /\n",
    "                                           df['target_cumcount'])\n",
    "        df['time_per_question_cat'] = np.int32(np.round(df['time_per_question'],-3).clip(lower=0,\n",
    "                                                                                upper=50000))\n",
    "        df = df.join(self.tpq, on='time_per_question_cat')\n",
    "        \n",
    "        df['lag_time_cat'] = np.int32(np.round(df['lag_time'],-3).clip(lower=-100000,\n",
    "                                                                       upper=500000))\n",
    "        \n",
    "        df['timestamp_prior_time_cumsum_diff']=df['timestamp']-df['prior_question_elapsed_time_cumsum']\n",
    "        \n",
    "        df['time_between_cat'] = np.int32(np.round(df['time_between'],-2).clip(upper=600000))\n",
    "        df = df.join(self.tb, on='time_between_cat')\n",
    "        \n",
    "        \n",
    "        if verbose: print('step 4 (add ratios) - Done')\n",
    "            \n",
    "        # step 2 merge question\n",
    "        df = df.join(self.questions_df.loc[self.questions_df.index.isin(df['content_id'])], on='content_id')\n",
    "        \n",
    "        # fillna fillna mainly for lectures\n",
    "        df = df.fillna({'prior_question_elapsed_time':0., 'prior_question_had_explanation':False,\n",
    "                        'bundle_id':0, 'part':0, 'tags':0, 'num_of_tags':0, 'bundle_size':0,\n",
    "                        'question_mean':0., 'question_std':0., 'question_skew':0.\n",
    "                        })\n",
    "        # change dtype\n",
    "        df = df.astype({'bundle_id':'int16', 'part':'int8', 'tags':'int16', 'num_of_tags':'int8',\n",
    "                        'bundle_size':'int8', 'prior_question_had_explanation':'bool',\n",
    "                        })\n",
    "        if verbose: print('step 2 (join questions_df) - Done')\n",
    "        \n",
    "        df['user_content_hmean'] = np.float16(2*((df['user_mean'] + 0.0001) * (df['question_mean'] + 0.0001)) /\n",
    "                                        (df['user_mean'] + df['question_mean']))\n",
    "        \n",
    "\n",
    "        df['all_hmean'] = np.float16(5*((df['user_mean'] + 0.0001) *\n",
    "                                        (df['question_mean'] + 0.0001) *\n",
    "                                        (df['tags_mean'] + 0.0001) * df['tpq_mean'] * df['tb_mean']) /\n",
    "                                     np.sum(df[['user_mean', 'question_mean', 'tags_mean',\n",
    "                                                'tpq_mean', 'tb_mean']], axis=1))\n",
    "        df['all_hsum'] = np.float16(np.sum(df[['user_mean', 'question_mean', 'tags_mean',\n",
    "                                               'tpq_mean', 'tb_mean']], axis=1))\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def save_data(self, df, name):\n",
    "        df.to_feather(self.path/(name + '.feather'))\n",
    "        \n",
    "    def load_data(self, name):\n",
    "        return pd.read_feather(self.path/(name + '.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Riiid(path=r'./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r.setup('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(r.user_hist_dict), Riiid.questions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(r.path/'train.csv', nrows=None, dtype=r.dtype, usecols=r.usecols)\n",
    "train_df = r.load_data('data') # 101 230 332\n",
    "# train_df = r.load_data('data_q') # 99 271 300\n",
    "\n",
    "# with open(r.path/'data_q.pickle', mode='rb') as file:\n",
    "#     train_df = pickle.load(file)\n",
    "\n",
    "# with open(r.path/'data_qr.pickle', mode='rb') as file:\n",
    "#     train_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do it once and then only load.\n",
    "# Riiid._set_up_questions_df(train_df)\n",
    "# with open(r.path/'questions_df.pickle', mode='wb') as file:\n",
    "#     pickle.dump(Riiid.questions_df, file)\n",
    "with open(r.path/'questions_df.pickle', mode='rb') as file:\n",
    "    Riiid.questions_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r.path/'tb.pickle', mode='rb') as file:\n",
    "    Riiid.tb = pickle.load(file)\n",
    "with open(r.path/'tpq.pickle', mode='rb') as file:\n",
    "    Riiid.tpq = pickle.load(file)\n",
    "# with open(r.path/'tptc.pickle', mode='rb') as file:\n",
    "#     Riiid.tptc = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r.path/'tptc.pickle', mode='wb') as file:\n",
    "#     pickle.dump(tptc, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.questions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r.path/'train_gr2_row_id.pickle', mode='rb') as file:\n",
    "    train_gr_row_id = pickle.load(file)\n",
    "with open(r.path/'val_gr2_row_id.pickle', mode='rb') as file:\n",
    "    val_gr_row_id = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df.loc[train_df['row_id'].isin(train_gr_row_id+val_gr_row_id)]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_df = r.transform_data(train_df, inference=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_df.columns), train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gr = train_df.loc[train_df['row_id'].isin(train_gr_row_id)].reset_index(drop=True)\n",
    "val_gr = train_df.loc[train_df['row_id'].isin(val_gr_row_id)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.save_data(train_gr, 'train_gr2_transformed')\n",
    "r.save_data(val_gr, 'val_gr2_transformed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.user_hist_dict[275030867]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_ = pd.read_csv(r.path/'example_test.csv')\n",
    "submission_df = pd.read_csv(r.path/'example_sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "bst = lgb.Booster(model_file = str(r.path) + '/models/lgb_g1-33f-l31-perfect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'answered_correctly'\n",
    "features = bst.feature_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr0 = test_df_.loc[test_df_['group_num']==0].copy()\n",
    "gr1 = test_df_.loc[test_df_['group_num']==1].copy()\n",
    "gr2 = test_df_.loc[test_df_['group_num']==2].copy()\n",
    "gr3 = test_df_.loc[test_df_['group_num']==3].copy()\n",
    "iter_test = [gr0, gr1, gr2, gr3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_test_df = None\n",
    "for test_df in iter_test:\n",
    "    \n",
    "    # from 2nd iteration, update user data\n",
    "    if prev_test_df is not None:\n",
    "        prev_test_df[target] = eval(test_df[\"prior_group_answers_correct\"].iat[0])\n",
    "        r.update_hist_data(prev_test_df)\n",
    "    \n",
    "    # save previous test_df\n",
    "    prev_test_df = test_df.copy()\n",
    "    \n",
    "    test_df = r.transform_data(test_df)\n",
    "    \n",
    "    test_df[target] =  bst.predict(test_df[features])\n",
    "#     test_df[target] =  bst_cat.predict(test_df[features])\n",
    "\n",
    "    sub = sub.append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features to check\n",
    "f=['user_id', 'bundle_id', 'timestamp', 'time_between', 'timestamp_prior_time_cumsum_diff', 'lag_time',\n",
    "   'prior_question_elapsed_time','prior_question_elapsed_time_cumsum',\n",
    "   'time_per_question','content_id', 'n_attempts','target_cumsum', 'target_cumcount', 'user_mean', 'answered_correctly'\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sub.loc[sub['user_id']==554169193,f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sub.loc[sub['user_id']==275030867,f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.user_hist_dict[554169193]['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %lprun -f function_name_only function_call_with_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f r.transform_data r.transform_data(test_df_, inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f r._scan_user_data r._scan_user_data(Riiid.user_hist_dict, test_df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(r.path/'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
