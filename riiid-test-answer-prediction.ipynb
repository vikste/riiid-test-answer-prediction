{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Riiid:\n",
    "    \n",
    "    path = None\n",
    "    \n",
    "    dtype={'row_id': 'int64', 'timestamp': 'int64',\n",
    "           'user_id': 'int32', 'content_id': 'int16',\n",
    "           'content_type_id': 'int8', 'task_container_id': 'int16',\n",
    "           'user_answer': 'int8', 'answered_correctly': 'int8',\n",
    "           'prior_question_elapsed_time': 'float32',\n",
    "           'prior_question_had_explanation': 'boolean',\n",
    "          }\n",
    "    \n",
    "    usecols=['timestamp', 'user_id', 'content_id',\n",
    "             'content_type_id','task_container_id',\n",
    "             'answered_correctly','user_answer',\n",
    "             'prior_question_elapsed_time','prior_question_had_explanation']\n",
    "    \n",
    "    questions_df = None\n",
    "    lectures_df = None\n",
    "    \n",
    "    train_user_target_stats = None\n",
    "    train_question_target_stats = None\n",
    "    \n",
    "    question_cumcount_hist = None\n",
    "    time_between_hist = None\n",
    "    prior_question_elapsed_time_cumsum_hist = None\n",
    "    \n",
    "    features = None\n",
    "    _na_dict = None\n",
    "    _dtype_dict = None\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _proc_question_tags(df):\n",
    "        return pd.concat([df.drop('tags', 1), df['tags'].str.get_dummies(sep=\" \")], 1)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_and_process_questions(cls):\n",
    "        \n",
    "        cls.questions_df = pd.read_csv(cls.path/'questions.csv')\n",
    "#         n_answer_options_df = pd.read_csv(cls.path/'n_answer_options.csv')\n",
    "        \n",
    "        # drop columns\n",
    "        cls.questions_df = cls.questions_df.drop(columns=['correct_answer'])\n",
    "        \n",
    "        # add number of tags\n",
    "        cls.questions_df['num_of_tags'] = cls.questions_df['tags'].map(lambda x: len(str(x).split()))\n",
    "        \n",
    "        # add number of questions in bundle\n",
    "        tmp = cls.questions_df[['question_id', 'bundle_id']] \\\n",
    "            .groupby('bundle_id').count() \\\n",
    "            .rename(columns={'question_id':'bundle_size'})\n",
    "        \n",
    "        cls.questions_df = cls.questions_df.join(tmp, on='bundle_id')\n",
    "#         cls.questions_df = cls.questions_df.join(n_answer_options_df, on='question_id')\n",
    "        \n",
    "        # one hot encode tags\n",
    "        #cls.questions_df = cls._proc_question_tags(cls.questions_df)\n",
    "        \n",
    "    @classmethod\n",
    "    def load_and_process_lectures(cls):\n",
    "        \n",
    "        cls.lectures_df = pd.read_csv(cls.path/'lectures.csv')\n",
    "\n",
    "        # process lectures data\n",
    "        cls.lectures_df['type_of'] = cls.lectures_df['type_of'].astype('category')\n",
    "#         types_of = ('type_starter', 'type_concept', 'type_intention', 'type_solving question')\n",
    "#         cls.lectures_df['type_of'].cat.set_categories(types_of, ordered=False, inplace=True)\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def set_data_path(cls, path):\n",
    "        cls.path = Path(path)\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_user_target_stats(cls, train):\n",
    "        \n",
    "        # user part\n",
    "        cls.train_user_target_stats = train.loc[train[train['content_type_id']==0].index,\n",
    "                                                ['user_id', 'answered_correctly']] \\\n",
    "            .groupby('user_id').agg(['mean', 'std', 'skew',])\n",
    "        \n",
    "        cls.train_user_target_stats.columns = cls.train_user_target_stats.columns.droplevel()\n",
    "        cls.train_user_target_stats.columns = ['user_mean', 'user_std', 'user_skew']\n",
    "        \n",
    "        cls.train_user_target_stats = cls.train_user_target_stats.astype(\n",
    "            dtype = {'user_mean':'float32', 'user_std':'float32', 'user_skew':'float32'})\n",
    "        \n",
    "        cls.train_user_target_stats.fillna(0.0, inplace=True)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_question_target_stats(cls, train):\n",
    "\n",
    "        # question part\n",
    "        cls.train_question_target_stats = train.loc[train[train['content_type_id']==0].index,\n",
    "                                                    ['content_id', 'answered_correctly']] \\\n",
    "            .groupby('content_id').agg(['mean', 'std', 'skew',])\n",
    "        \n",
    "        cls.train_question_target_stats.columns = cls.train_question_target_stats.columns.droplevel()\n",
    "        cls.train_question_target_stats.columns = ['question_mean', 'question_std', 'question_skew']\n",
    "        \n",
    "        cls.train_question_target_stats = cls.train_question_target_stats.astype(\n",
    "            dtype = {'question_mean':'float32', 'question_std':'float32', 'question_skew':'float32'})\n",
    "        \n",
    "        cls.train_question_target_stats.fillna(0.0, inplace=True)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _make_question_cumcount(df):\n",
    "        \"\"\"For test/validation datasets only.\"\"\"\n",
    "        \n",
    "        df['question_cumcount'] = df[['user_id', 'content_type_id', 'content_id']]\\\n",
    "                .groupby(['user_id', 'content_type_id']).transform('cumcount') + 1\n",
    "        \n",
    "        tmp = pd.Series(data=Riiid.question_cumcount_hist.values(),\n",
    "                        index=Riiid.question_cumcount_hist.keys(),\n",
    "                        name='tmp')\n",
    "        \n",
    "        df['question_cumcount'] += df.join(tmp, on='user_id')\\\n",
    "                                     .fillna({'tmp':0})\\\n",
    "                                     .astype({'tmp':'int16'})['tmp']\n",
    "        \n",
    "        Riiid.question_cumcount_hist.update(\n",
    "            df[df['content_type_id']==0][['user_id', 'question_cumcount']]\\\n",
    "                .groupby('user_id')\\\n",
    "                .max()\\\n",
    "                .to_dict()['question_cumcount'])\n",
    "\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def _make_prior_question_elapsed_time_cumsum(df):\n",
    "        \"\"\"For test/validation datasets only.\"\"\"\n",
    "        \n",
    "        df['prior_question_elapsed_time_cumsum'] = df[['user_id', 'content_type_id', 'prior_question_elapsed_time']]\\\n",
    "                .groupby(['user_id', 'content_type_id']).transform('cumsum')\n",
    "        \n",
    "        tmp = pd.Series(data=Riiid.prior_question_elapsed_time_cumsum_hist.values(),\n",
    "                        index=Riiid.prior_question_elapsed_time_cumsum_hist.keys(),\n",
    "                        name='tmp')\n",
    "        \n",
    "        df['prior_question_elapsed_time_cumsum'] += df.join(tmp, on='user_id')\\\n",
    "                                     .fillna({'tmp':0})\\\n",
    "                                     .astype({'tmp':int})['tmp']\n",
    "        \n",
    "        Riiid.prior_question_elapsed_time_cumsum_hist.update(\n",
    "            df[df['content_type_id']==0][['user_id', 'prior_question_elapsed_time_cumsum']]\\\n",
    "                .groupby('user_id')\\\n",
    "                .max()\\\n",
    "                .to_dict()['prior_question_elapsed_time_cumsum'])\n",
    "\n",
    "        return df        \n",
    "    \n",
    "    @staticmethod\n",
    "    def _make_time_between(df):\n",
    "        \"\"\"For test/validation datasets only.\"\"\"     \n",
    "        \n",
    "        tmp = pd.Series(data=Riiid.time_between_hist.values(),\n",
    "                        index=Riiid.time_between_hist.keys(),\n",
    "                        name='tmp')\n",
    "        \n",
    "        df['time_between'] = df[['user_id', 'content_type_id', 'timestamp']]\\\n",
    "                .groupby(['user_id', 'content_type_id']).transform('diff')\n",
    "        \n",
    "        df['time_between'] = df['time_between'].where(~df['time_between'].isna(),\n",
    "                                                      df['timestamp'] - df.join(tmp, on='user_id')\\\n",
    "                                                        .fillna({'tmp':0})['tmp'])\\\n",
    "                                               .astype({'time_between':'int64'})\n",
    "\n",
    "        Riiid.time_between_hist.update(\n",
    "            df[df['content_type_id']==0][['user_id', 'timestamp']]\\\n",
    "                .groupby('user_id')\\\n",
    "                .max().to_dict()['timestamp'])\n",
    "\n",
    "        return df\n",
    "        \n",
    "    def setup_data_stats(self, df):\n",
    "        \n",
    "        if Riiid.train_user_target_stats is None:\n",
    "            Riiid._get_user_target_stats(df)\n",
    "        print('train_user_target_stats - Done')\n",
    "        \n",
    "        if Riiid.train_question_target_stats is None:\n",
    "            Riiid._get_question_target_stats(df)\n",
    "        print('train_question_target_stats - Done')\n",
    "        \n",
    "        if Riiid._dtype_dict is None:\n",
    "            Riiid._dtype_dict = df.dtypes.to_dict()\n",
    "        print('_dtype_dict - Done')\n",
    "        \n",
    "        if Riiid._na_dict is None:\n",
    "            Riiid._na_dict = {\n",
    "                              'part': 0,\n",
    "                              'num_of_tags': 0,\n",
    "                              'bundle_size': 0,\n",
    "#                               'n_answer_options': 0,\n",
    "                              'question_mean': Riiid.train_question_target_stats['question_mean'].mean(axis=0),\n",
    "                              'question_std': Riiid.train_question_target_stats['question_std'].mean(axis=0),\n",
    "                              'question_skew': Riiid.train_question_target_stats['question_skew'].mean(axis=0),\n",
    "                             }\n",
    "        print('_na_dict - Done')\n",
    "    \n",
    "    @classmethod\n",
    "    def get_features(self, df):\n",
    "        # save features\n",
    "        if Riiid.features is None:\n",
    "            Riiid.features = list(df.columns)\n",
    "            Riiid.features.remove('answered_correctly')\n",
    "    \n",
    "    def transform_data(self, df, test=False, verbose=False):\n",
    "        \n",
    "        if not test: # we need questions and lectures for test\n",
    "            # step 0 = keep questions only\n",
    "            df = df.loc[df[df['content_type_id']==0].index]\n",
    "            if verbose: print('step 0 (keep questions only) - Done')\n",
    "\n",
    "        # step 1 = fillna for prior_question_elapsed_time and prior_question_had_explanation\n",
    "        df = df.fillna({'prior_question_elapsed_time':0.,\n",
    "                        'prior_question_had_explanation':False})\n",
    "        if verbose: print('step 1 (fillna: prior_question_elapsed_time & prior_question_had_explanation) - Done')\n",
    "        \n",
    "        # step 2 merge question without question_id, content_type_id and tags\n",
    "        df = df.join(self.questions_df, on='content_id') \\\n",
    "               .drop(columns=['question_id',\n",
    "#                               'content_type_id',\n",
    "                              'tags'])\n",
    "        \n",
    "        # fillna fillna mainly for lectures\n",
    "        df = df.fillna({'prior_question_elapsed_time':0.,\n",
    "                        'prior_question_had_explanation':False,\n",
    "                        'bundle_id':0, 'num_of_tags':0, 'bundle_size':0,\n",
    "                        'part':0, 'n_answer_options':0})\n",
    "        # change dtype\n",
    "        df = df.astype({'bundle_id':'int16', 'num_of_tags':'int8',\n",
    "                        'bundle_size':'int8', 'prior_question_had_explanation':'bool',\n",
    "                        'part':'int8',\n",
    "#                         'n_answer_options':'int8'\n",
    "                       })\n",
    "        \n",
    "        if verbose: print('step 2 (merge questions_df) - Done')\n",
    "               \n",
    "        # step 3 merge question target stats\n",
    "        df = df.join(self.train_question_target_stats, on='content_id')\n",
    "        if verbose: print('step 3 (merge train_question_target_stats) - Done')\n",
    "        \n",
    "        # step 4 merge train_user_target_stats\n",
    "#         df = df.join(self.train_user_target_stats, on='user_id')\n",
    "#         if verbose: print('step 4 (merge train_user_target_stats) - Done')\n",
    "        \n",
    "        # step 4a add time_between\n",
    "        if test:\n",
    "            df = self._make_time_between(df)\n",
    "        else:\n",
    "            df['time_between'] = df[['user_id', 'timestamp']].groupby('user_id').diff().fillna(0.).astype(int)        \n",
    "        if verbose: print('step 4a (add time_between) - Done')\n",
    "            \n",
    "        # step 4b add question_cumcount\n",
    "        if test:\n",
    "            df = self._make_question_cumcount(df)\n",
    "        else:\n",
    "            df['question_cumcount'] = df[['user_id', 'content_id']]\\\n",
    "                .groupby(['user_id']).cumcount().astype('int16')        \n",
    "        if verbose: print('step 4b (add question_cumcount) - Done')\n",
    "        \n",
    "        # step 4c add prior_question_elapsed_time_cumsum\n",
    "        if test:\n",
    "            df = self._make_prior_question_elapsed_time_cumsum(df)\n",
    "        else:\n",
    "            df['prior_question_elapsed_time_cumsum'] = df[['user_id', 'prior_question_elapsed_time']]\\\n",
    "                .groupby('user_id').cumsum().astype(int)\n",
    "        if verbose: print('step 4c (add prior_question_elapsed_time_cumsum) - Done')\n",
    "            \n",
    "        # step 4d add time_per_question\n",
    "        df['time_per_question']=(df['prior_question_elapsed_time_cumsum'] / df['question_cumcount'])\\\n",
    "                .fillna(0.).replace(np.inf, 0.).astype('float32')\n",
    "        if verbose: print('step 4d (add time_per_question) - Done')\n",
    "            \n",
    "        # step 4e add tb_int\n",
    "        df['tb_int']=df['time_between'].round(-5).astype(int)\n",
    "        if verbose: print('step 4e (add tb_int) - Done')\n",
    "            \n",
    "            \n",
    "        # step 5 fill remaining NAs (using _na_dict)\n",
    "        if test and self._na_dict is not None:\n",
    "            df = df.fillna(self._na_dict)\n",
    "        if verbose: print('step 5 (fill remaining NAs) - Done')\n",
    "        \n",
    "        # step 6 convert dtypes (using _na_dict)\n",
    "        if test and self._dtype_dict is not None:\n",
    "            df = df.astype(self._dtype_dict)\n",
    "        if verbose: print('step 6 (convert dtypes) - Done')\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def split_data(self, df, n_iter=30):\n",
    "        \"\"\"Split into train and validation datasets.\"\"\"\n",
    "        \n",
    "        counter = 0\n",
    "        train_idx = df.index\n",
    "        val_idx = pd.RangeIndex(start=0, stop=0, step=1)\n",
    "    \n",
    "        while counter < n_iter:\n",
    "            tmp_val_flag = (df.loc[train_idx, ['user_id', 'timestamp']]\\\n",
    "                            .groupby('user_id')\\\n",
    "                            .transform(max).squeeze() == df.loc[train_idx,'timestamp'])\n",
    "        \n",
    "            tmp_val_index = df.loc[train_idx][tmp_val_flag].index\n",
    "        \n",
    "            val_idx = val_idx.append(tmp_val_index).sort_values()\n",
    "            train_idx = train_idx.drop(tmp_val_index)\n",
    "            counter += 1\n",
    "    \n",
    "        return train_idx.to_list(), val_idx.to_list()\n",
    "    \n",
    "    \n",
    "    def save_data(self, df, name):\n",
    "        df.to_feather(self.path/(name + '.feather'))\n",
    "        \n",
    "    def load_data(self, name):\n",
    "        return pd.read_feather(self.path/(name + '.feather'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Riiid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.set_data_path(path=r'./data')\n",
    "r.load_and_process_questions()\n",
    "r.load_and_process_lectures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.save_data(data_df, name='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_idx, val_idx = r.split_data(train_df, n_iter=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_idx), len(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.save_data(train_df.iloc[train_idx].reset_index(drop=True), name='train_p1')\n",
    "# r.save_data(train_df.iloc[val_idx].reset_index(drop=True), name='train_p2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(r.path/'train.csv', nrows=200000, dtype=r.dtype, usecols=r.usecols)\n",
    "# train_df = r.load_data('data')\n",
    "# train_df = r.load_data('train')\n",
    "# train_df = r.load_data('train_p1')\n",
    "train_df = r.load_data('train_p2')\n",
    "# val_df = r.load_data('val') # we load transformed below\n",
    "# val_df_p1 = r.load_data('val_p1')\n",
    "val_df_p2 = r.load_data('val_p2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.questions_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.lectures_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.lectures_df['type_of'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.setup_data_stats(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r.path/'train_user_target_stats.pickle', mode='rb') as file:\n",
    "#     Riiid.train_user_target_stats = pickle.load(file)\n",
    "# with open(r.path/'train_question_target_stats.pickle', mode='rb') as file:\n",
    "#     Riiid.train_question_target_stats = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r.path/'data_user_target_stats.pickle', mode='rb') as file:\n",
    "    Riiid.train_user_target_stats = pickle.load(file)\n",
    "with open(r.path/'data_question_target_stats.pickle', mode='rb') as file:\n",
    "    Riiid.train_question_target_stats = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r.path/'train_user_target_stats.pickle', mode='wb') as file:\n",
    "#     pickle.dump(r.train_user_target_stats, file)\n",
    "# with open(r.path/'train_question_target_stats.pickle', mode='wb') as file:\n",
    "#     pickle.dump(r.train_question_target_stats, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r.path/'data_user_target_stats.pickle', mode='wb') as file:\n",
    "#     pickle.dump(r.train_user_target_stats, file)\n",
    "# with open(r.path/'data_question_target_stats.pickle', mode='wb') as file:\n",
    "#     pickle.dump(r.train_question_target_stats, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.train_user_target_stats.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.train_question_target_stats.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_df.shape,\n",
    "# val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = r.transform_data(train_df, verbose=True)\n",
    "# train_df = r.load_data('train_p2_transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r.path/'train_time_between_hist.pickle', mode='rb') as file:\n",
    "#     Riiid.time_between_hist = pickle.load(file)\n",
    "# with open(r.path/'train_question_cumcount_hist.pickle', mode='rb') as file:\n",
    "#     Riiid.question_cumcount_hist = pickle.load(file)\n",
    "# with open(r.path/'train_prior_question_elapsed_time_cumsum_hist.pickle', mode='rb') as file:\n",
    "#     Riiid.prior_question_elapsed_time_cumsum_hist = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r.path/'train_p1_time_between_hist.pickle', mode='rb') as file:\n",
    "#     Riiid.time_between_hist = pickle.load(file)\n",
    "# with open(r.path/'train_p1_question_cumcount_hist.pickle', mode='rb') as file:\n",
    "#     Riiid.question_cumcount_hist = pickle.load(file)\n",
    "# with open(r.path/'train_p1_prior_question_elapsed_time_cumsum_hist.pickle', mode='rb') as file:\n",
    "#     Riiid.prior_question_elapsed_time_cumsum_hist = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r.path/'train_p2_time_between_hist.pickle', mode='rb') as file:\n",
    "    Riiid.time_between_hist = pickle.load(file)\n",
    "with open(r.path/'train_p2_question_cumcount_hist.pickle', mode='rb') as file:\n",
    "    Riiid.question_cumcount_hist = pickle.load(file)\n",
    "with open(r.path/'train_p2_prior_question_elapsed_time_cumsum_hist.pickle', mode='rb') as file:\n",
    "    Riiid.prior_question_elapsed_time_cumsum_hist = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riiid.time_between_hist = train_df[['user_id', 'timestamp']].groupby(['user_id']).max().to_dict()['timestamp']\n",
    "# Riiid.question_cumcount_hist = train_df[['user_id', 'question_cumcount']]\\\n",
    "#             .groupby(['user_id']).max().to_dict()['question_cumcount']\n",
    "# Riiid.prior_question_elapsed_time_cumsum_hist = train_df[['user_id', 'prior_question_elapsed_time_cumsum']]\\\n",
    "#             .groupby(['user_id']).max().to_dict()['prior_question_elapsed_time_cumsum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r.path/'train_p1_time_between_hist.pickle', mode='wb') as file:\n",
    "#     pickle.dump(Riiid.time_between_hist, file)\n",
    "# with open(r.path/'train_p1_question_cumcount_hist.pickle', mode='wb') as file:\n",
    "#     pickle.dump(Riiid.question_cumcount_hist, file)\n",
    "# with open(r.path/'train_p1_prior_question_elapsed_time_cumsum_hist.pickle', mode='wb') as file:\n",
    "#     pickle.dump(Riiid.prior_question_elapsed_time_cumsum_hist, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r.path/'data_time_between_hist.pickle', mode='wb') as file:\n",
    "#     pickle.dump(Riiid.time_between_hist, file)\n",
    "# with open(r.path/'data_question_cumcount_hist.pickle', mode='wb') as file:\n",
    "#     pickle.dump(Riiid.question_cumcount_hist, file)\n",
    "# with open(r.path/'data_prior_question_elapsed_time_cumsum_hist.pickle', mode='wb') as file:\n",
    "#     pickle.dump(Riiid.prior_question_elapsed_time_cumsum_hist, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(r.time_between_hist), len(r.question_cumcount_hist), len(r.prior_question_elapsed_time_cumsum_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "# r.save_data(train_df, 'data_transformed')\n",
    "r.save_data(train_df, 'train_p2_transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Riiid._dtype_dict = None\n",
    "Riiid._na_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.setup_data_stats(train_df) # refactor to setup_dtype_na_dict or similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r._na_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r._dtype_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r.path/'train_p2_na_dict.pickle', mode='wb') as file:\n",
    "#     pickle.dump(Riiid._na_dict, file)\n",
    "# with open(r.path/'train_p2_dtype_dict.pickle', mode='wb') as file:\n",
    "#     pickle.dump(Riiid._dtype_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r.path/'train_p2_na_dict.pickle', mode='rb') as file:\n",
    "    Riiid._na_dict = pickle.load(file)\n",
    "with open(r.path/'train_p2_dtype_dict.pickle', mode='rb') as file:\n",
    "    Riiid._dtype_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# val_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_df = r.transform_data(val_df, test=True, verbose=True)\n",
    "val_df = r.transform_data(val_df_p2, test=True, verbose=True)\n",
    "# val_df = r.load_data('val_transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.save_data(val_df, 'val_transformed')\n",
    "r.save_data(val_df, 'val_p2_transformed_base_p2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.get_features(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.features)\n",
    "print(len(r.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.features.remove('user_id')\n",
    "r.features.remove('content_type_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['timestamp', 'user_id']].groupby('user_id').max().join(\n",
    "    val_df[['timestamp', 'user_id']].groupby('user_id').min(), how='outer',lsuffix='_train_max', rsuffix='_val_min').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = r.load_data('train_p2_transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_p1 = r.load_data('val_p1_transformed')\n",
    "val_df_p2 = r.load_data('val_p2_transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.get_features(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.features.remove('user_id')\n",
    "r.features.remove('content_type_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= r.features\n",
    "target = 'answered_correctly'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r.path/'models/rf-train-small-model.sav', 'rb') as f:\n",
    "    rf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'n_estimators':40,\n",
    "        'criterion':'entropy',\n",
    "        'max_depth':None,\n",
    "        'min_samples_split':2,\n",
    "        'min_samples_leaf':1,\n",
    "        'min_weight_fraction_leaf':0.0,\n",
    "        'max_features':1.0,\n",
    "        'max_leaf_nodes':None,\n",
    "        'min_impurity_decrease':0.0,\n",
    "        'min_impurity_split':None,\n",
    "        'bootstrap':True,\n",
    "        'oob_score':False,\n",
    "        'n_jobs':-1,\n",
    "        'random_state':37,\n",
    "        'verbose':1,\n",
    "        'warm_start':False,\n",
    "        'class_weight':None,\n",
    "        'ccp_alpha':0.0,\n",
    "        'max_samples':200000,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(train_df[features].values, train_df[target].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r.path/'models/rf-train-small-model.sav', 'wb') as f:\n",
    "    pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_p1_preds = rf.predict_proba(val_df_p1[features])[:,1]\n",
    "val_p2_preds = rf.predict_proba(val_df_p2[features])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_p1_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(val_df_p2[target].values.squeeze(), val_p2_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(train_df[target], preds.mean(0)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_estimators = np.stack([t.predict_proba(val_df_p1[features]) for t in rf.estimators_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_estimators.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_estimators[:0+1,:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([roc_auc_score(val_df_p1[target], preds_estimators[:i+1,:,1].mean(0)) for i in range(len(rf.estimators_))]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fi = rf_feat_importance(rf, val_df_p1[features])\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fi(fi):\n",
    "    return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\n",
    "\n",
    "plot_fi(fi);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = rf.predict_proba(val_df_p1.loc[:,features])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,5))\n",
    "plt.margins(x=0.01, y=0.1)\n",
    "plt.plot(rf.feature_importances_[np.argsort(rf.feature_importances_)][-10:], 'bo')\n",
    "plt.xticks(np.arange(10),\n",
    "           np.array(features)[np.argsort(rf.feature_importances_)][-10:],\n",
    "           fontsize = 'small', rotation = 90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=train_df[features], label=train_df[target], weight=None,\n",
    "                     base_margin=None, missing=None,\n",
    "                     silent=False, feature_names=features,\n",
    "                     feature_types=None, nthread=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dval1 = xgb.DMatrix(data=val_df_p1[features], label=val_df_p1[target], weight=None,\n",
    "                     base_margin=None, missing=None,\n",
    "                     silent=False, feature_names=features,\n",
    "                     feature_types=None, nthread=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dval2 = xgb.DMatrix(data=val_df_p2[features], label=val_df_p2[target], weight=None,\n",
    "                     base_margin=None, missing=None,\n",
    "                     silent=False, feature_names=features,\n",
    "                     feature_types=None, nthread=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dval.save_binary(r.path/'dval.xgboost', silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dval.get_base_margin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'learning_rate':0.1,\n",
    "        'max_depth':5,\n",
    "        'eval_metric': 'auc',\n",
    "        'objective':'binary:logistic'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(params, dtrain=dtrain, num_boost_round=50, evals=[(dtrain,'train'), (dval1,'val_p1'), (dval2,'val_p2')], obj=None, feval=None,\n",
    "          maximize=False, early_stopping_rounds=None, evals_result=None,\n",
    "          verbose_eval=10, xgb_model=None, callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = r.load_data('data_transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['bundle_size']==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['user_id'] == 2147470777].to_csv('2147470777.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['tb_int'] = train_df['time_between'].round(decimals=-5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_df[['tb_int', 'answered_correctly']].groupby('tb_int').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.reset_index()['tb_int'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[tmp['answered_correctly']<0.1].reset_index().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tmp['answered_correctly'], bins=10)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(tmp[tmp['answered_correctly']>0.9].index, bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(tmp[tmp['answered_correctly']<0.1].index, bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p2 = r.load_data('train_p2_transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_p1, val_p2 = r.load_data('val_p1_transformed'), r.load_data('val_p2_transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p2.head()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
