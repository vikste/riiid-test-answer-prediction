{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Riiid:\n",
    "    \n",
    "    path = None\n",
    "    \n",
    "    dtype={'row_id': 'int64', 'timestamp': 'int64',\n",
    "           'user_id': 'int32', 'content_id': 'int16',\n",
    "           'content_type_id': 'int8', 'task_container_id': 'int16',\n",
    "           'user_answer': 'int8', 'answered_correctly': 'int8',\n",
    "           'prior_question_elapsed_time': 'float32',\n",
    "           'prior_question_had_explanation': 'boolean',\n",
    "          }\n",
    "    \n",
    "    usecols=['timestamp', 'user_id', 'content_id',\n",
    "             'content_type_id','task_container_id',\n",
    "             'answered_correctly',\n",
    "             'prior_question_elapsed_time','prior_question_had_explanation']\n",
    "    \n",
    "    questions_df = None\n",
    "    lectures_df = None\n",
    "    \n",
    "    stats_user_target = None\n",
    "    stats_question_target = None\n",
    "\n",
    "    hist_question_cumcount = pd.DataFrame(columns=['question_cumcount'])\n",
    "    hist_time_between = pd.DataFrame(columns=['timestamp'])\n",
    "    hist_prior_question_elapsed_time_cumsum = pd.DataFrame(columns=['prior_question_elapsed_time_cumsum'])\n",
    "    hist_target_cumsum = pd.DataFrame(columns=['target_cumsum'])\n",
    "    \n",
    "    features = None\n",
    "    _na_dict = None\n",
    "    _dtype_dict = None\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _proc_question_tags(df):\n",
    "        return pd.concat([df.drop('tags', 1), df['tags'].str.get_dummies(sep=\" \")], 1)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_and_process_questions(cls):\n",
    "        \n",
    "        cls.questions_df = pd.read_csv(cls.path/'questions.csv')\n",
    "        \n",
    "        # drop columns\n",
    "        cls.questions_df = cls.questions_df.drop(columns=['correct_answer'])\n",
    "        \n",
    "        # add number of tags\n",
    "        cls.questions_df['num_of_tags'] = cls.questions_df['tags'].map(lambda x: len(str(x).split()))\n",
    "        \n",
    "        # add number of questions in bundle\n",
    "        tmp = cls.questions_df[['question_id', 'bundle_id']] \\\n",
    "            .groupby('bundle_id').count() \\\n",
    "            .rename(columns={'question_id':'bundle_size'})\n",
    "        \n",
    "        cls.questions_df = cls.questions_df.join(tmp, on='bundle_id')\n",
    "        \n",
    "        # one hot encode tags\n",
    "        #cls.questions_df = cls._proc_question_tags(cls.questions_df)\n",
    "        \n",
    "    @classmethod\n",
    "    def load_and_process_lectures(cls):\n",
    "        \n",
    "        cls.lectures_df = pd.read_csv(cls.path/'lectures.csv')\n",
    "\n",
    "        # process lectures data\n",
    "        cls.lectures_df['type_of'] = cls.lectures_df['type_of'].astype('category')\n",
    "#         types_of = ('type_starter', 'type_concept', 'type_intention', 'type_solving question')\n",
    "#         cls.lectures_df['type_of'].cat.set_categories(types_of, ordered=False, inplace=True)\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def set_data_path(cls, path):\n",
    "        cls.path = Path(path)\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_user_target_stats(cls, train):\n",
    "        \n",
    "        # user part\n",
    "        cls.stats_user_target = train.loc[train['content_type_id']==0,\n",
    "                                          ['user_id', 'answered_correctly']] \\\n",
    "            .groupby('user_id').agg(['mean', 'std', 'skew',])\n",
    "        \n",
    "        cls.stats_user_target.columns = cls.stats_user_target.columns.droplevel()\n",
    "        cls.stats_user_target.columns = ['user_mean', 'user_std', 'user_skew']\n",
    "        \n",
    "        cls.stats_user_target = cls.stats_user_target.astype(\n",
    "            dtype = {'user_mean':'float32', 'user_std':'float32', 'user_skew':'float32'})\n",
    "        \n",
    "        cls.stats_user_target.fillna(0.0, inplace=True)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_question_target_stats(cls, train):\n",
    "\n",
    "        # question part\n",
    "        cls.stats_question_target = train.loc[train['content_type_id']==0,\n",
    "                                              ['content_id', 'answered_correctly']] \\\n",
    "            .groupby('content_id').agg(['mean', 'std', 'skew',])\n",
    "        \n",
    "        cls.stats_question_target.columns = cls.stats_question_target.columns.droplevel()\n",
    "        cls.stats_question_target.columns = ['question_mean', 'question_std', 'question_skew']\n",
    "        \n",
    "        cls.stats_question_target = cls.stats_question_target.astype(\n",
    "            dtype = {'question_mean':'float32', 'question_std':'float32', 'question_skew':'float32'})\n",
    "        \n",
    "        cls.stats_question_target.fillna(0.0, inplace=True)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _make_question_cumcount(df, inference=True, prev_group=None):\n",
    "        \"\"\"For test/validation datasets only.\"\"\"\n",
    "        \n",
    "        if inference:\n",
    "            if prev_group is not None:\n",
    "                # collect data from previous group first\n",
    "                prev_group['question_cumcount'] = prev_group[['user_id', 'content_type_id', 'content_id']]\\\n",
    "                    .groupby(['user_id', 'content_type_id']).transform('cumcount') + 1\n",
    "            \n",
    "        \n",
    "                prev_group['question_cumcount'] += prev_group.join(Riiid.hist_question_cumcount,\n",
    "                                                                   on='user_id',\n",
    "                                                                   rsuffix='_tmp')\\\n",
    "                                     .fillna({'question_cumcount_tmp':0})\\\n",
    "                                     .astype({'question_cumcount_tmp':'int16'})['question_cumcount_tmp']\n",
    "            \n",
    "                # update hist_question_cumcount with collected data\n",
    "                Riiid.hist_question_cumcount = pd.concat([Riiid.hist_question_cumcount,\n",
    "                                                      prev_group.loc[prev_group['content_type_id']==0,\n",
    "                                                             ['user_id', 'question_cumcount']]\\\n",
    "                                                      .groupby('user_id').max()])\n",
    "        \n",
    "                Riiid.hist_question_cumcount = Riiid.hist_question_cumcount[\n",
    "                    ~Riiid.hist_question_cumcount.index.duplicated(keep='last')]\n",
    "                \n",
    "                # and then build question_cumcount for current group\n",
    "                df['question_cumcount'] = 0\n",
    "        \n",
    "                df['question_cumcount'] += df.join(Riiid.hist_question_cumcount, on='user_id', rsuffix='_tmp')\\\n",
    "                                     .fillna({'question_cumcount_tmp':0})\\\n",
    "                                     .astype({'question_cumcount_tmp':'int16'})['question_cumcount_tmp']\n",
    "            \n",
    "            \n",
    "            else:\n",
    "                # build question_cumcount for current group\n",
    "                df['question_cumcount'] = 0\n",
    "        \n",
    "                df['question_cumcount'] += df.join(Riiid.hist_question_cumcount, on='user_id', rsuffix='_tmp')\\\n",
    "                                     .fillna({'question_cumcount_tmp':0})\\\n",
    "                                     .astype({'question_cumcount_tmp':'int16'})['question_cumcount_tmp']\n",
    "        else:\n",
    "            # not for inference\n",
    "            df['question_cumcount'] = df[['user_id', 'content_type_id', 'content_id']]\\\n",
    "                .groupby(['user_id', 'content_type_id']).transform('cumcount') + 1\n",
    "        \n",
    "            df['question_cumcount'] += df.join(Riiid.hist_question_cumcount, on='user_id', rsuffix='_tmp')\\\n",
    "                                     .fillna({'question_cumcount_tmp':0})\\\n",
    "                                     .astype({'question_cumcount_tmp':'int16'})['question_cumcount_tmp']\n",
    "        \n",
    "            #update hist\n",
    "            Riiid.hist_question_cumcount = pd.concat([Riiid.hist_question_cumcount,\n",
    "                                                      df.loc[df['content_type_id']==0,\n",
    "                                                             ['user_id', 'question_cumcount']]\\\n",
    "                                                      .groupby('user_id').max()])\n",
    "        \n",
    "            Riiid.hist_question_cumcount = Riiid.hist_question_cumcount[\n",
    "                    ~Riiid.hist_question_cumcount.index.duplicated(keep='last')]\n",
    "\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def _make_target_cumsum(df, inference=True, prev_group=None):\n",
    "        \"\"\"For test/validation datasets only.\"\"\"\n",
    "        \n",
    "        if inference:\n",
    "            if prev_group is not None:\n",
    "                # collect data from previous group first\n",
    "                prev_group['target_cumsum'] = prev_group[['user_id', 'content_type_id', 'answered_correctly']]\\\n",
    "                    .groupby(['user_id', 'content_type_id']).transform('cumsum')\n",
    "                \n",
    "                prev_group['target_cumsum'] += prev_group.join(Riiid.hist_target_cumsum,\n",
    "                                                               on='user_id',\n",
    "                                                               rsuffix='_tmp')\\\n",
    "                                     .fillna({'target_cumsum_tmp':0})\\\n",
    "                                     .astype({'target_cumsum_tmp':int})['target_cumsum_tmp']\n",
    "                \n",
    "                # update hist_target_cumsum with collected data\n",
    "                Riiid.hist_target_cumsum = pd.concat([Riiid.hist_target_cumsum,\n",
    "                                                      prev_group.loc[prev_group['content_type_id']==0,\n",
    "                                                             ['user_id', 'target_cumsum']]\\\n",
    "                                                      .groupby('user_id').max()])\n",
    "        \n",
    "                Riiid.hist_target_cumsum = Riiid.hist_target_cumsum[\n",
    "                    ~Riiid.hist_target_cumsum.index.duplicated(keep='last')]                \n",
    "\n",
    "                #build target_cumsum for current group\n",
    "                df['target_cumsum'] = 0\n",
    "                \n",
    "                # Assume that the 1st answer is correct (fillna with 1)\n",
    "                df['target_cumsum'] += df.join(Riiid.hist_target_cumsum, on='user_id', rsuffix='_tmp')\\\n",
    "                    .fillna({'target_cumsum_tmp':1})\\\n",
    "                    .astype({'target_cumsum_tmp':int})['target_cumsum_tmp']                 \n",
    "            else:\n",
    "                # build target_cumsum for current group\n",
    "                df['target_cumsum']=0\n",
    "                \n",
    "                # Assume that the 1st answer is correct (fillna with 1)\n",
    "                df['target_cumsum'] += df.join(Riiid.hist_target_cumsum, on='user_id', rsuffix='_tmp')\\\n",
    "                    .fillna({'target_cumsum_tmp':1})\\\n",
    "                    .astype({'target_cumsum_tmp':int})['target_cumsum_tmp'] \n",
    "        else:\n",
    "            # not for inference\n",
    "            df['target_cumsum'] = df[['user_id', 'content_type_id', 'answered_correctly']]\\\n",
    "                .groupby(['user_id', 'content_type_id']).transform('cumsum')\n",
    "        \n",
    "            df['target_cumsum'] += df.join(Riiid.hist_target_cumsum, on='user_id', rsuffix='_tmp')\\\n",
    "                                     .fillna({'target_cumsum_tmp':0})\\\n",
    "                                     .astype({'target_cumsum_tmp':int})['target_cumsum_tmp']\n",
    "        \n",
    "            #update hist\n",
    "            Riiid.hist_target_cumsum = pd.concat([Riiid.hist_target_cumsum,\n",
    "                                                      df.loc[df['content_type_id']==0,\n",
    "                                                             ['user_id', 'target_cumsum']]\\\n",
    "                                                      .groupby('user_id').max()])\n",
    "        \n",
    "            Riiid.hist_target_cumsum = Riiid.hist_target_cumsum[\n",
    "                    ~Riiid.hist_target_cumsum.index.duplicated(keep='last')] \n",
    "\n",
    "        return df \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _make_prior_question_elapsed_time_cumsum(df):\n",
    "        \"\"\"For test/validation datasets only.\"\"\"\n",
    "        \n",
    "        df['prior_question_elapsed_time_cumsum'] = df[['user_id', 'content_type_id', 'prior_question_elapsed_time']]\\\n",
    "                .groupby(['user_id', 'content_type_id']).transform('cumsum')\n",
    "        \n",
    "        df['prior_question_elapsed_time_cumsum'] += df.join(Riiid.hist_prior_question_elapsed_time_cumsum,\n",
    "                                                            on='user_id', rsuffix='_tmp')\\\n",
    "                                     .fillna({'prior_question_elapsed_time_cumsum_tmp':0})\\\n",
    "                                     .astype({'prior_question_elapsed_time_cumsum_tmp':int})[\n",
    "            'prior_question_elapsed_time_cumsum_tmp']\n",
    "        \n",
    "        # update history\n",
    "        Riiid.hist_prior_question_elapsed_time_cumsum = pd.concat([Riiid.hist_prior_question_elapsed_time_cumsum,\n",
    "                                                      df.loc[df['content_type_id']==0,\n",
    "                                                             ['user_id', 'prior_question_elapsed_time_cumsum']]\\\n",
    "                                                      .groupby('user_id').max()])\n",
    "        \n",
    "        Riiid.hist_prior_question_elapsed_time_cumsum = Riiid.hist_prior_question_elapsed_time_cumsum[\n",
    "                    ~Riiid.hist_prior_question_elapsed_time_cumsum.index.duplicated(keep='last')] \n",
    "\n",
    "        return df        \n",
    "    \n",
    "    @staticmethod\n",
    "    def _make_time_between(df):\n",
    "        \"\"\"For test/validation datasets only.\"\"\"\n",
    "        \n",
    "        df['time_between'] = df[['user_id', 'content_type_id', 'timestamp']]\\\n",
    "                .groupby(['user_id', 'content_type_id']).transform('diff')\n",
    "        \n",
    "        s = df.join(Riiid.hist_time_between,\n",
    "                    on='user_id',\n",
    "                    rsuffix='_tmp').fillna({'timestamp_tmp':0})['timestamp_tmp'].values\n",
    "\n",
    "        df['time_between'] = np.where(~df['time_between'].isna(),\n",
    "                                      df['time_between'].values,\n",
    "                                      df['timestamp'].values - s)\n",
    "        df['time_between'] = df['time_between'].astype({'time_between':'int64'})\n",
    "        \n",
    "        #update hist\n",
    "        Riiid.hist_time_between = pd.concat([Riiid.hist_time_between,\n",
    "                                             df.loc[df['content_type_id']==0, ['user_id', 'timestamp']]\\\n",
    "                                             .groupby('user_id').max()])\n",
    "        \n",
    "        Riiid.hist_time_between = Riiid.hist_time_between[~Riiid.hist_time_between.index.duplicated(keep='last')]\n",
    "\n",
    "        return df\n",
    "        \n",
    "    def setup_data_stats(self, df):\n",
    "        \n",
    "        if Riiid.stats_user_target is None:\n",
    "            Riiid._get_user_target_stats(df)\n",
    "        print('train_user_target_stats - Done')\n",
    "        \n",
    "        if Riiid.stats_question_target is None:\n",
    "            Riiid._get_question_target_stats(df)\n",
    "        print('train_question_target_stats - Done')\n",
    "        \n",
    "        if Riiid._dtype_dict is None:\n",
    "            Riiid._dtype_dict = df.dtypes.to_dict()\n",
    "            del Riiid._dtype_dict['answered_correctly']\n",
    "        print('_dtype_dict - Done')\n",
    "        \n",
    "        if Riiid._na_dict is None:\n",
    "            Riiid._na_dict = {\n",
    "                              'part': 0,\n",
    "                              'num_of_tags': 0,\n",
    "                              'bundle_size': 0,\n",
    "                              'question_mean': Riiid.stats_question_target['question_mean'].mean(axis=0),\n",
    "                              'question_std': Riiid.stats_question_target['question_std'].mean(axis=0),\n",
    "                              'question_skew': Riiid.stats_question_target['question_skew'].mean(axis=0),\n",
    "                             }\n",
    "        print('_na_dict - Done')\n",
    "    \n",
    "    @classmethod\n",
    "    def get_features(self, df):\n",
    "        # save features\n",
    "        if Riiid.features is None:\n",
    "            Riiid.features = list(df.columns)\n",
    "            Riiid.features.remove('answered_correctly')\n",
    "    \n",
    "    def transform_data(self, df, test=False, verbose=False, inference=True, prev_group=None):\n",
    "        \n",
    "        if not test: # we need questions and lectures for test\n",
    "            # step 0 = keep questions only\n",
    "            df = df.loc[df[df['content_type_id']==0].index]\n",
    "            if verbose: print('step 0 (keep questions only) - Done')\n",
    "\n",
    "        # step 1 = fillna for prior_question_elapsed_time and prior_question_had_explanation\n",
    "        df = df.fillna({'prior_question_elapsed_time':0.,\n",
    "                        'prior_question_had_explanation':False})\n",
    "        if verbose: print('step 1 (fillna: prior_question_elapsed_time & prior_question_had_explanation) - Done')\n",
    "        \n",
    "        # step 2 merge question without question_id, and tags\n",
    "        df = df.join(self.questions_df, on='content_id') \\\n",
    "               .drop(columns=['question_id',\n",
    "                              'tags'])\n",
    "        \n",
    "        # fillna fillna mainly for lectures\n",
    "        df = df.fillna({'prior_question_elapsed_time':0.,\n",
    "                        'prior_question_had_explanation':False,\n",
    "                        'bundle_id':0, 'num_of_tags':0, 'bundle_size':0,\n",
    "                        'part':0, 'n_answer_options':0})\n",
    "        # change dtype\n",
    "        df = df.astype({'bundle_id':'int16', 'num_of_tags':'int8',\n",
    "                        'bundle_size':'int8', 'prior_question_had_explanation':'bool',\n",
    "                        'part':'int8',\n",
    "                       })\n",
    "        \n",
    "        if verbose: print('step 2 (merge questions_df) - Done')\n",
    "               \n",
    "        # step 3 merge question target stats\n",
    "        df = df.join(self.stats_question_target, on='content_id')\n",
    "        if verbose: print('step 3 (merge question_target_stats) - Done')\n",
    "        \n",
    "        # step 4 merge train_user_target_stats\n",
    "#         df = df.join(self.stats_train_user_target, on='user_id')\n",
    "#         if verbose: print('step 4 (merge train_user_target_stats) - Done')\n",
    "        \n",
    "        # step 4a add time_between\n",
    "        if test:\n",
    "            df = self._make_time_between(df)\n",
    "        else:\n",
    "            df['time_between'] = df[['user_id', 'timestamp']].groupby('user_id').diff().fillna(0.).astype(int)        \n",
    "        if verbose: print('step 4a (add time_between) - Done')\n",
    "            \n",
    "        # step 4b add question_cumcount\n",
    "        if test:\n",
    "            df = self._make_question_cumcount(df, inference=inference, prev_group=prev_group)\n",
    "        else:\n",
    "            df['question_cumcount'] = df[['user_id', 'content_id']]\\\n",
    "                .groupby(['user_id']).cumcount().astype('int16') + 1        \n",
    "        if verbose: print('step 4b (add question_cumcount) - Done')\n",
    "        \n",
    "        # step 4c add target_cumsum\n",
    "        if test:\n",
    "            df = self._make_target_cumsum(df, inference=inference, prev_group=prev_group)\n",
    "        else:\n",
    "            df['target_cumsum'] = df[['user_id', 'answered_correctly']]\\\n",
    "                .groupby('user_id').cumsum().astype(int)\n",
    "        if verbose: print('step 4c (add target_cumsum) - Done')\n",
    "            \n",
    "        # step 4d add prior_question_elapsed_time_cumsum\n",
    "        if test:\n",
    "            df = self._make_prior_question_elapsed_time_cumsum(df)\n",
    "        else:\n",
    "            df['prior_question_elapsed_time_cumsum'] = df[['user_id', 'prior_question_elapsed_time']]\\\n",
    "                .groupby('user_id').cumsum().astype(int)\n",
    "        if verbose: print('step 4d (add prior_question_elapsed_time_cumsum) - Done')\n",
    "            \n",
    "        # step 4e add user_mean\n",
    "        df['user_mean']=(df['target_cumsum'] / df['question_cumcount'])\\\n",
    "                .fillna(0.).replace(np.inf, 0.).astype('float32')\n",
    "        if verbose: print('step 4e (add user_mean) - Done')\n",
    "            \n",
    "        # step 4f add time_per_question\n",
    "        df['time_per_question']=(df['prior_question_elapsed_time_cumsum'] / df['question_cumcount'])\\\n",
    "                .fillna(0.).replace(np.inf, 0.).astype('float32')\n",
    "        if verbose: print('step 4f (add time_per_question) - Done')\n",
    "            \n",
    "        # step 4g add timestamp_prior_time_cumsum_diff\n",
    "        df['timestamp_prior_time_cumsum_diff']=df['timestamp']-df['prior_question_elapsed_time_cumsum']\n",
    "        if verbose: print('step 4g (add timestamp_prior_time_cumsum_diff) - Done')\n",
    "                   \n",
    "            \n",
    "        # step 5 fill remaining NAs (using _na_dict)\n",
    "        if test and self._na_dict is not None:\n",
    "            df = df.fillna(self._na_dict)\n",
    "        if verbose: print('step 5 (fill remaining NAs) - Done')\n",
    "        \n",
    "        # step 6 convert dtypes (using _na_dict)\n",
    "        \n",
    "        if test and self._dtype_dict is not None:\n",
    "            df = df.astype(self._dtype_dict)\n",
    "        if verbose: print('step 6 (convert dtypes) - Done')\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def split_data(self, df, n_iter=30):\n",
    "        \"\"\"Split into train and validation datasets.\"\"\"\n",
    "        \n",
    "        counter = 0\n",
    "        train_idx = df.index\n",
    "        val_idx = pd.RangeIndex(start=0, stop=0, step=1)\n",
    "    \n",
    "        while counter < n_iter:\n",
    "            tmp_val_flag = (df.loc[train_idx, ['user_id', 'timestamp']]\\\n",
    "                            .groupby('user_id')\\\n",
    "                            .transform(max).squeeze() == df.loc[train_idx,'timestamp'])\n",
    "        \n",
    "            tmp_val_index = df.loc[train_idx][tmp_val_flag].index\n",
    "        \n",
    "            val_idx = val_idx.append(tmp_val_index).sort_values()\n",
    "            train_idx = train_idx.drop(tmp_val_index)\n",
    "            counter += 1\n",
    "    \n",
    "        return train_idx.to_list(), val_idx.to_list()\n",
    "    \n",
    "    \n",
    "    def save_data(self, df, name):\n",
    "        df.to_feather(self.path/(name + '.feather'))\n",
    "        \n",
    "    def load_data(self, name):\n",
    "        return pd.read_feather(self.path/(name + '.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Riiid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.set_data_path(path=r'./data')\n",
    "r.load_and_process_questions()\n",
    "r.load_and_process_lectures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.save_data(data_df, name='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_idx, val_idx = r.split_data(train_df, n_iter=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_idx), len(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.save_data(train_df.iloc[train_idx].reset_index(drop=True), name='train_p1')\n",
    "# r.save_data(train_df.iloc[val_idx].reset_index(drop=True), name='train_p2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(r.path/'train.csv', nrows=200000, dtype=r.dtype, usecols=r.usecols)\n",
    "# train_df = r.load_data('data') # 101 230 332\n",
    "# train_df = r.load_data('train') #88 777 729\n",
    "# train_df = r.load_data('train_p1') # 68 999 539\n",
    "# train_df = r.load_data('train_p2') # 19 778 190\n",
    "train_df = r.load_data('train_m') # 23 630 479\n",
    "# val_df = r.load_data('val') # 12 452 603\n",
    "# val_df_p1 = r.load_data('val_p1') # 6 101 188\n",
    "# val_df_p2 = r.load_data('val_p2') # 6 351 415\n",
    "val_df = r.load_data('val_m') # 3 433 724"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>5692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56943</td>\n",
       "      <td>115</td>\n",
       "      <td>5716</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  content_type_id  task_container_id  \\\n",
       "0          0      115        5692                0                  1   \n",
       "1      56943      115        5716                0                  2   \n",
       "\n",
       "   answered_correctly  prior_question_elapsed_time  \\\n",
       "0                   1                          NaN   \n",
       "1                   1                      37000.0   \n",
       "\n",
       "   prior_question_had_explanation  \n",
       "0                            <NA>  \n",
       "1                           False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23630479, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534187</td>\n",
       "      <td>115</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>557677</td>\n",
       "      <td>115</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  content_type_id  task_container_id  \\\n",
       "0     534187      115          45                0                 22   \n",
       "1     557677      115         185                0                 23   \n",
       "\n",
       "   answered_correctly  prior_question_elapsed_time  \\\n",
       "0                   0                      19000.0   \n",
       "1                   0                      21000.0   \n",
       "\n",
       "   prior_question_had_explanation  \n",
       "0                           False  \n",
       "1                           False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3433724, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>part</th>\n",
       "      <th>tags</th>\n",
       "      <th>num_of_tags</th>\n",
       "      <th>bundle_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51 131 162 38</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131 36 81</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id  bundle_id  part           tags  num_of_tags  bundle_size\n",
       "0            0          0     1  51 131 162 38            4            1\n",
       "1            1          1     1      131 36 81            3            1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.questions_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lecture_id</th>\n",
       "      <th>tag</th>\n",
       "      <th>part</th>\n",
       "      <th>type_of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>159</td>\n",
       "      <td>5</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lecture_id  tag  part  type_of\n",
       "0          89  159     5  concept\n",
       "1         100   70     1  concept"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.lectures_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['concept', 'intention', 'solving question', 'starter'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.lectures_df['type_of'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.setup_data_stats(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r.path/'data_stats_user_target.pickle', mode='rb') as file:\n",
    "    Riiid.stats_user_target = pickle.load(file)\n",
    "with open(r.path/'data_stats_question_target.pickle', mode='rb') as file:\n",
    "    Riiid.stats_question_target = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r.path/'data_stats_user_target.pickle', mode='wb') as file:\n",
    "#     pickle.dump(Riiid.stats_user_target, file)\n",
    "# with open(r.path/'data_stats_question_target.pickle', mode='wb') as file:\n",
    "#     pickle.dump(Riiid.stats_question_target, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_mean</th>\n",
       "      <th>user_std</th>\n",
       "      <th>user_skew</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.465215</td>\n",
       "      <td>-0.879359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.430183</td>\n",
       "      <td>1.328338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_mean  user_std  user_skew\n",
       "user_id                                \n",
       "115       0.695652  0.465215  -0.879359\n",
       "124       0.233333  0.430183   1.328338"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.stats_user_target.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_mean</th>\n",
       "      <th>question_std</th>\n",
       "      <th>question_skew</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.907721</td>\n",
       "      <td>0.289440</td>\n",
       "      <td>-2.818128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.890646</td>\n",
       "      <td>0.312104</td>\n",
       "      <td>-2.503986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            question_mean  question_std  question_skew\n",
       "content_id                                            \n",
       "0                0.907721      0.289440      -2.818128\n",
       "1                0.890646      0.312104      -2.503986"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.stats_question_target.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23630479, 8), (3433724, 8))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_df.shape,\n",
    "val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 (keep questions only) - Done\n",
      "step 1 (fillna: prior_question_elapsed_time & prior_question_had_explanation) - Done\n",
      "step 2 (merge questions_df) - Done\n",
      "step 3 (merge question_target_stats) - Done\n",
      "step 4a (add time_between) - Done\n",
      "step 4b (add question_cumcount) - Done\n",
      "step 4c (add target_cumsum) - Done\n",
      "step 4d (add prior_question_elapsed_time_cumsum) - Done\n",
      "step 4e (add user_mean) - Done\n",
      "step 4f (add time_per_question) - Done\n",
      "step 4g (add timestamp_prior_time_cumsum_diff) - Done\n",
      "step 5 (fill remaining NAs) - Done\n",
      "step 6 (convert dtypes) - Done\n"
     ]
    }
   ],
   "source": [
    "train_df = r.transform_data(train_df, verbose=True, inference=False)\n",
    "# train_df = r.load_data('train_transformed')\n",
    "# train_df = r.load_data('train_p2_transformed')\n",
    "# train_df = r.load_data('data_transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Riiid.hist_time_between = train_df[['user_id', 'timestamp']].groupby(['user_id']).max()\n",
    "Riiid.hist_question_cumcount = train_df[['user_id', 'question_cumcount']]\\\n",
    "            .groupby(['user_id']).max()\n",
    "Riiid.hist_prior_question_elapsed_time_cumsum = train_df[['user_id', 'prior_question_elapsed_time_cumsum']]\\\n",
    "            .groupby(['user_id']).max()\n",
    "Riiid.hist_target_cumsum = train_df[['user_id', 'target_cumsum']]\\\n",
    "            .groupby(['user_id']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r.path/'train_m_hist_time_between.pickle', mode='wb') as file:\n",
    "    pickle.dump(Riiid.hist_time_between, file)\n",
    "with open(r.path/'train_m_hist_question_cumcount.pickle', mode='wb') as file:\n",
    "    pickle.dump(Riiid.hist_question_cumcount, file)\n",
    "with open(r.path/'train_m_hist_prior_question_elapsed_time_cumsum.pickle', mode='wb') as file:\n",
    "    pickle.dump(Riiid.hist_prior_question_elapsed_time_cumsum, file)\n",
    "with open(r.path/'train_m_hist_target_cumsum.pickle', mode='wb') as file:\n",
    "    pickle.dump(Riiid.hist_target_cumsum, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116335, 116335, 116335, 116335)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r.hist_time_between), len(r.hist_question_cumcount), len(r.hist_prior_question_elapsed_time_cumsum), len(r.hist_target_cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riiid.hist_prior_question_elapsed_time_cumsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>part</th>\n",
       "      <th>...</th>\n",
       "      <th>question_mean</th>\n",
       "      <th>question_std</th>\n",
       "      <th>question_skew</th>\n",
       "      <th>time_between</th>\n",
       "      <th>question_cumcount</th>\n",
       "      <th>target_cumsum</th>\n",
       "      <th>prior_question_elapsed_time_cumsum</th>\n",
       "      <th>user_mean</th>\n",
       "      <th>time_per_question</th>\n",
       "      <th>timestamp_prior_time_cumsum_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>5692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>5692</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745495</td>\n",
       "      <td>0.435589</td>\n",
       "      <td>-1.127249</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56943</td>\n",
       "      <td>115</td>\n",
       "      <td>5716</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>5716</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734901</td>\n",
       "      <td>0.441395</td>\n",
       "      <td>-1.064443</td>\n",
       "      <td>56943</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18500.0</td>\n",
       "      <td>19943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  content_type_id  task_container_id  \\\n",
       "0          0      115        5692                0                  1   \n",
       "1      56943      115        5716                0                  2   \n",
       "\n",
       "   answered_correctly  prior_question_elapsed_time  \\\n",
       "0                   1                          0.0   \n",
       "1                   1                      37000.0   \n",
       "\n",
       "   prior_question_had_explanation  bundle_id  part  ...  question_mean  \\\n",
       "0                           False       5692     5  ...       0.745495   \n",
       "1                           False       5716     5  ...       0.734901   \n",
       "\n",
       "   question_std  question_skew  time_between  question_cumcount  \\\n",
       "0      0.435589      -1.127249             0                  1   \n",
       "1      0.441395      -1.064443         56943                  2   \n",
       "\n",
       "   target_cumsum  prior_question_elapsed_time_cumsum  user_mean  \\\n",
       "0              1                                   0        1.0   \n",
       "1              2                               37000        1.0   \n",
       "\n",
       "   time_per_question  timestamp_prior_time_cumsum_diff  \n",
       "0                0.0                                 0  \n",
       "1            18500.0                             19943  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>part</th>\n",
       "      <th>...</th>\n",
       "      <th>question_mean</th>\n",
       "      <th>question_std</th>\n",
       "      <th>question_skew</th>\n",
       "      <th>time_between</th>\n",
       "      <th>question_cumcount</th>\n",
       "      <th>target_cumsum</th>\n",
       "      <th>prior_question_elapsed_time_cumsum</th>\n",
       "      <th>user_mean</th>\n",
       "      <th>time_per_question</th>\n",
       "      <th>timestamp_prior_time_cumsum_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>5692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>5692</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745495</td>\n",
       "      <td>0.435589</td>\n",
       "      <td>-1.127249</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56943</td>\n",
       "      <td>115</td>\n",
       "      <td>5716</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>5716</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734901</td>\n",
       "      <td>0.441395</td>\n",
       "      <td>-1.064443</td>\n",
       "      <td>56943</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18500.000000</td>\n",
       "      <td>19943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118363</td>\n",
       "      <td>115</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966869</td>\n",
       "      <td>0.178984</td>\n",
       "      <td>-5.217423</td>\n",
       "      <td>61420</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>92000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30666.666016</td>\n",
       "      <td>26363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131167</td>\n",
       "      <td>115</td>\n",
       "      <td>7860</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>7860</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954815</td>\n",
       "      <td>0.207714</td>\n",
       "      <td>-4.379650</td>\n",
       "      <td>12804</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>111000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27750.000000</td>\n",
       "      <td>20167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137965</td>\n",
       "      <td>115</td>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>7922</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953218</td>\n",
       "      <td>0.211178</td>\n",
       "      <td>-4.292724</td>\n",
       "      <td>6798</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>122000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24400.000000</td>\n",
       "      <td>15965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  content_type_id  task_container_id  \\\n",
       "0          0      115        5692                0                  1   \n",
       "1      56943      115        5716                0                  2   \n",
       "2     118363      115         128                0                  0   \n",
       "3     131167      115        7860                0                  3   \n",
       "4     137965      115        7922                0                  4   \n",
       "\n",
       "   answered_correctly  prior_question_elapsed_time  \\\n",
       "0                   1                          0.0   \n",
       "1                   1                      37000.0   \n",
       "2                   1                      55000.0   \n",
       "3                   1                      19000.0   \n",
       "4                   1                      11000.0   \n",
       "\n",
       "   prior_question_had_explanation  bundle_id  part  ...  question_mean  \\\n",
       "0                           False       5692     5  ...       0.745495   \n",
       "1                           False       5716     5  ...       0.734901   \n",
       "2                           False        128     1  ...       0.966869   \n",
       "3                           False       7860     1  ...       0.954815   \n",
       "4                           False       7922     1  ...       0.953218   \n",
       "\n",
       "   question_std  question_skew  time_between  question_cumcount  \\\n",
       "0      0.435589      -1.127249             0                  1   \n",
       "1      0.441395      -1.064443         56943                  2   \n",
       "2      0.178984      -5.217423         61420                  3   \n",
       "3      0.207714      -4.379650         12804                  4   \n",
       "4      0.211178      -4.292724          6798                  5   \n",
       "\n",
       "   target_cumsum  prior_question_elapsed_time_cumsum  user_mean  \\\n",
       "0              1                                   0        1.0   \n",
       "1              2                               37000        1.0   \n",
       "2              3                               92000        1.0   \n",
       "3              4                              111000        1.0   \n",
       "4              5                              122000        1.0   \n",
       "\n",
       "   time_per_question  timestamp_prior_time_cumsum_diff  \n",
       "0           0.000000                                 0  \n",
       "1       18500.000000                             19943  \n",
       "2       30666.666016                             26363  \n",
       "3       27750.000000                             20167  \n",
       "4       24400.000000                             15965  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['user_id'] == 115].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Riiid._dtype_dict = None\n",
    "Riiid._na_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.setup_data_stats(train_df) # refactor to setup_dtype_na_dict or similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Riiid._na_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Riiid._dtype_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r.path/'data_na_dict.pickle', mode='wb') as file:\n",
    "    pickle.dump(Riiid._na_dict, file)\n",
    "with open(r.path/'data_dtype_dict.pickle', mode='wb') as file:\n",
    "    pickle.dump(Riiid._dtype_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "# r.save_data(train_df, 'data_transformed')\n",
    "# r.save_data(train_df, 'train_transformed')\n",
    "# r.save_data(train_df, 'train_p1_transformed')\n",
    "r.save_data(train_df, 'train_m_transformed')\n",
    "# r.save_data(train_df, 'train_p2_transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r.path/'train_p1_hist_time_between.pickle', mode='rb') as file:\n",
    "    Riiid.hist_time_between = pickle.load(file)\n",
    "with open(r.path/'train_p1_hist_question_cumcount.pickle', mode='rb') as file:\n",
    "    Riiid.hist_question_cumcount = pickle.load(file)\n",
    "with open(r.path/'train_p1_hist_prior_question_elapsed_time_cumsum.pickle', mode='rb') as file:\n",
    "    Riiid.hist_prior_question_elapsed_time_cumsum = pickle.load(file)\n",
    "with open(r.path/'train_p1_hist_target_cumsum.pickle', mode='rb') as file:\n",
    "    Riiid.hist_target_cumsum = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r.path/'data_na_dict.pickle', mode='rb') as file:\n",
    "    Riiid._na_dict = pickle.load(file)\n",
    "with open(r.path/'data_dtype_dict.pickle', mode='rb') as file:\n",
    "    Riiid._dtype_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# val_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 (fillna: prior_question_elapsed_time & prior_question_had_explanation) - Done\n",
      "step 2 (merge questions_df) - Done\n",
      "step 3 (merge question_target_stats) - Done\n",
      "step 4a (add time_between) - Done\n",
      "step 4b (add question_cumcount) - Done\n",
      "step 4c (add target_cumsum) - Done\n",
      "step 4d (add prior_question_elapsed_time_cumsum) - Done\n",
      "step 4e (add user_mean) - Done\n",
      "step 4f (add time_per_question) - Done\n",
      "step 4g (add timestamp_prior_time_cumsum_diff) - Done\n",
      "step 5 (fill remaining NAs) - Done\n",
      "step 6 (convert dtypes) - Done\n"
     ]
    }
   ],
   "source": [
    "val_df = r.transform_data(val_df, test=True, verbose=True, inference=False)\n",
    "# train_df = r.transform_data(train_df, test=True, verbose=True, inference=False)\n",
    "# val_df = r.transform_data(val_df_p2, test=True, verbose=True, inference=False)\n",
    "# val_df = r.load_data('val_transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.save_data(val_df, 'val_m_transformed')\n",
    "# r.save_data(val_df, 'val_p2_transformed')\n",
    "# r.save_data(train_df, 'train_p2_transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp                             0\n",
       "user_id                               0\n",
       "content_id                            0\n",
       "content_type_id                       0\n",
       "task_container_id                     0\n",
       "answered_correctly                    0\n",
       "prior_question_elapsed_time           0\n",
       "prior_question_had_explanation        0\n",
       "bundle_id                             0\n",
       "part                                  0\n",
       "num_of_tags                           0\n",
       "bundle_size                           0\n",
       "question_mean                         0\n",
       "question_std                          0\n",
       "question_skew                         0\n",
       "time_between                          0\n",
       "question_cumcount                     0\n",
       "target_cumsum                         0\n",
       "prior_question_elapsed_time_cumsum    0\n",
       "user_mean                             0\n",
       "time_per_question                     0\n",
       "timestamp_prior_time_cumsum_diff      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3433724, 22)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.get_features(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.features)\n",
    "print(len(r.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r.features.remove('user_id')\n",
    "r.features.remove('content_type_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['user_id']==115].tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[val_df['user_id']==115].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['timestamp', 'user_id']].groupby('user_id').max().join(\n",
    "    val_df[['timestamp', 'user_id']].groupby('user_id').min(), how='outer',lsuffix='_train_max', rsuffix='_val_min').isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = r.load_data('train_p2_transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_p1 = r.load_data('val_p1_transformed')\n",
    "val_df_p2 = r.load_data('val_p2_transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.get_features(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.features.remove('user_id')\n",
    "r.features.remove('content_type_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= r.features\n",
    "target = 'answered_correctly'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r.path/'models/rf-train-small-model.sav', 'rb') as f:\n",
    "    rf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'n_estimators':40,\n",
    "        'criterion':'entropy',\n",
    "        'max_depth':None,\n",
    "        'min_samples_split':2,\n",
    "        'min_samples_leaf':1,\n",
    "        'min_weight_fraction_leaf':0.0,\n",
    "        'max_features':1.0,\n",
    "        'max_leaf_nodes':None,\n",
    "        'min_impurity_decrease':0.0,\n",
    "        'min_impurity_split':None,\n",
    "        'bootstrap':True,\n",
    "        'oob_score':False,\n",
    "        'n_jobs':-1,\n",
    "        'random_state':37,\n",
    "        'verbose':1,\n",
    "        'warm_start':False,\n",
    "        'class_weight':None,\n",
    "        'ccp_alpha':0.0,\n",
    "        'max_samples':200000,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(train_df[features].values, train_df[target].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r.path/'models/rf-train-small-model.sav', 'wb') as f:\n",
    "    pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_p1_preds = rf.predict_proba(val_df_p1[features])[:,1]\n",
    "val_p2_preds = rf.predict_proba(val_df_p2[features])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_p1_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(val_df_p2[target].values.squeeze(), val_p2_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(train_df[target], preds.mean(0)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_estimators = np.stack([t.predict_proba(val_df_p1[features]) for t in rf.estimators_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_estimators.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_estimators[:0+1,:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([roc_auc_score(val_df_p1[target], preds_estimators[:i+1,:,1].mean(0)) for i in range(len(rf.estimators_))]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fi = rf_feat_importance(rf, val_df_p1[features])\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fi(fi):\n",
    "    return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\n",
    "\n",
    "plot_fi(fi);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = rf.predict_proba(val_df_p1.loc[:,features])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,5))\n",
    "plt.margins(x=0.01, y=0.1)\n",
    "plt.plot(rf.feature_importances_[np.argsort(rf.feature_importances_)][-10:], 'bo')\n",
    "plt.xticks(np.arange(10),\n",
    "           np.array(features)[np.argsort(rf.feature_importances_)][-10:],\n",
    "           fontsize = 'small', rotation = 90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=train_df[features], label=train_df[target], weight=None,\n",
    "                     base_margin=None, missing=None,\n",
    "                     silent=False, feature_names=features,\n",
    "                     feature_types=None, nthread=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dval1 = xgb.DMatrix(data=val_df_p1[features], label=val_df_p1[target], weight=None,\n",
    "                     base_margin=None, missing=None,\n",
    "                     silent=False, feature_names=features,\n",
    "                     feature_types=None, nthread=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dval2 = xgb.DMatrix(data=val_df_p2[features], label=val_df_p2[target], weight=None,\n",
    "                     base_margin=None, missing=None,\n",
    "                     silent=False, feature_names=features,\n",
    "                     feature_types=None, nthread=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dval.save_binary(r.path/'dval.xgboost', silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dval.get_base_margin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'learning_rate':0.1,\n",
    "        'max_depth':5,\n",
    "        'eval_metric': 'auc',\n",
    "        'objective':'binary:logistic'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(params, dtrain=dtrain, num_boost_round=50, evals=[(dtrain,'train'), (dval1,'val_p1'), (dval2,'val_p2')], obj=None, feval=None,\n",
    "          maximize=False, early_stopping_rounds=None, evals_result=None,\n",
    "          verbose_eval=10, xgb_model=None, callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 351 415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_idx(df, n_iter=17):\n",
    "        \"\"\"Split into train and validation datasets.\"\"\"\n",
    "        \n",
    "        counter = 0\n",
    "        val_idx = []\n",
    "    \n",
    "        while counter < n_iter:\n",
    "            train_trans = df[['user_id', 'timestamp']].groupby('user_id').transform('max').values\n",
    "            val_filter = (train_trans.squeeze() == df['timestamp'].values)\n",
    "            val_idx.extend(df.iloc[val_filter].index.to_list())\n",
    "            df.drop(index=df.iloc[val_filter].index, inplace=True)\n",
    "            \n",
    "            counter += 1\n",
    "    \n",
    "        return val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = get_val_idx(train_, n_iter=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = train_df.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_df['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ = val_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "val_idx = get_val_idx(val_, n_iter=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.iloc[~train_df.index.isin(val_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_ = pd.read_csv(r.path/'example_test.csv')\n",
    "submission_df = pd.read_csv(r.path/'example_sample_submission.csv')\n",
    "val_df = r.load_data('val_p2_transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'row_id':55, 'group_num':0, 'timestamp':5000, 'user_id':275030867,\n",
    "     'content_id':0, 'content_type_id':1, 'task_container_id':1,\n",
    "     'prior_question_elapsed_time':13000.0, 'prior_question_had_explanation':True,\n",
    "     'prior_group_answers_correct':np.nan, 'prior_group_responses':np.nan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_ = test_df_.append(d, ignore_index=True)\n",
    "l = eval(test_df_.iat[18,9])\n",
    "l.append(-1)\n",
    "test_df_.iat[18,9] = str(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r.path/'data_stats_user_target.pickle', mode='rb') as file:\n",
    "    Riiid.stats_user_target = pickle.load(file)\n",
    "with open(r.path/'data_stats_question_target.pickle', mode='rb') as file:\n",
    "    Riiid.stats_question_target = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r.path/'data_na_dict.pickle', mode='rb') as file:\n",
    "    Riiid._na_dict = pickle.load(file)\n",
    "with open(r.path/'data_dtype_dict.pickle', mode='rb') as file:\n",
    "    Riiid._dtype_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r.path/'data_hist_time_between.pickle', mode='rb') as file:\n",
    "    Riiid.hist_time_between = pickle.load(file)\n",
    "with open(r.path/'data_hist_question_cumcount.pickle', mode='rb') as file:\n",
    "    Riiid.hist_question_cumcount = pickle.load(file)\n",
    "with open(r.path/'data_hist_prior_question_elapsed_time_cumsum.pickle', mode='rb') as file:\n",
    "    Riiid.hist_prior_question_elapsed_time_cumsum = pickle.load(file)\n",
    "with open(r.path/'data_hist_target_cumsum.pickle', mode='rb') as file:\n",
    "    Riiid.hist_target_cumsum = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "bst = lgb.Booster(model_file = str(r.path) + '/models/lgb_p2_75')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'answered_correctly'\n",
    "features = ['content_id', 'prior_question_elapsed_time',\n",
    "            'prior_question_had_explanation', 'bundle_id', 'part',\n",
    "            'num_of_tags', 'bundle_size', 'question_mean',\n",
    "            'question_std', 'question_skew', 'time_between',\n",
    "            'question_cumcount', 'target_cumsum',\n",
    "            'prior_question_elapsed_time_cumsum', 'user_mean',\n",
    "            'time_per_question', 'timestamp_prior_time_cumsum_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(columns=['row_id', target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "prev_test_df = None\n",
    "\n",
    "for g in range(4):\n",
    "    test_df = test_df_[test_df_['group_num']==g].copy()\n",
    "    \n",
    "    \n",
    "    if prev_test_df is None:\n",
    "        prev_test_df = test_df.copy()\n",
    "        test_df = r.transform_data(test_df, test=True,inference=True, prev_group=None)\n",
    "        test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop=True)\n",
    "        \n",
    "    else:\n",
    "        current_test = test_df.copy()\n",
    "        prev_test_df[target] = eval(test_df[\"prior_group_answers_correct\"].iat[0])\n",
    "        \n",
    "        test_df = r.transform_data(current_test, test=True, inference=True, prev_group=prev_test_df)\n",
    "        test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop=True)\n",
    "        prev_test_df = current_test.copy()\n",
    "        \n",
    "    test_df[target] =  bst.predict(test_df[features])\n",
    "\n",
    "    \n",
    "    sub = sub.append(test_df[['row_id', target]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %lprun -f function_name_only function_call_with_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f r.transform_data r.transform_data(test_df_, test=True, inference=True, prev_group=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f r._make_time_between r._make_time_between(test_df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f r._make_target_cumsum r._make_target_cumsum(test_df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f r._make_question_cumcount r._make_question_cumcount(test_df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f r._make_prior_question_elapsed_time_cumsum r._make_prior_question_elapsed_time_cumsum(test_df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub.join(submission['answered_correctly'], rsuffix='_sub').iloc[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(r.path/'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
